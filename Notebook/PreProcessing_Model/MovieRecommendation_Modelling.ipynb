{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab16e12-1af8-4f46-b86a-8c783c03a440",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1190db52-967b-4690-8b22-1d7e772cce95",
   "metadata": {},
   "source": [
    "## Contents:\n",
    " \n",
    " * Introduction\n",
    " \n",
    " * Sourcing and Loading\n",
    "   * Importing relevant libraries\n",
    " \n",
    " * Dataset\n",
    "   * Preparing the datasets\n",
    "\n",
    " * Features Importance Using Deep & Cross Network (DCN-V2)\n",
    "   * Deep and cross network (DCN) came out of Google Research, and is designed to learn explicit and bounded-degree cross features effectively\n",
    "   * Feature Cross\n",
    "   * Cross Network\n",
    "   * Deep & Cross Network\n",
    "   * Model Structure\n",
    "   * Model construction\n",
    "   * Model Training\n",
    "   * DCN (stacked)\n",
    "   * Low-rank DCN\n",
    "   * DNN (Cross Layer = False)\n",
    "   \n",
    "   \n",
    " * The Two-Tower and Ranking Models\n",
    "   * Case 1: Baseline\n",
    "       * A Multi-Task Model\n",
    "           * Rating-specialized model\n",
    "\t\t   * Retrieval-specialized model\n",
    "\t\t   * Joint model: Baseline\n",
    "            * Summary of the Baseline Joint Model\n",
    "           \n",
    "   * Case 2: Tuned Joint Model\n",
    "        * Implementing a Retrieval Model\n",
    "\t\t* A Multi-Task Model\n",
    "\t\t* Joint model\n",
    "        \n",
    " * Summary of all models' metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e4ee80-72db-4d51-b9e4-97337ae6cec5",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a149a4-fcf4-4ac4-876b-7eea11266e8d",
   "metadata": {},
   "source": [
    "For this final notebook, we will be dealing with:\n",
    "\n",
    "- The Feature importance using Deep and Cross Network (DCN-v2)\n",
    "\n",
    "- Training multiple TensorFlow Recommenders.\n",
    "\n",
    "- Applying hyperparameters tuning where applicable to ensure every algorithm will result in the best prediction possible.\n",
    "\n",
    "- Finally, evaluating these Models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eacf0d6-6203-41bf-8b46-8ebde7c52d4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sourcing and Loading\n",
    "**Importing relevant libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7c863e7-4c78-48cb-8393-d13c13cc4bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary Libararies: \n",
    "\n",
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from typing import Dict, Text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35ac035-d5c8-4770-b292-a957de719da7",
   "metadata": {},
   "source": [
    "## Dataset: \n",
    "\n",
    "**Movie Lens** contains a set of movie ratings from the MovieLens website, a movie recommendation service. This dataset was collected and maintained by [GroupLens](https://grouplens.org/) , a research group at the University of Minnesota. There are 5 versions that include: \"25m\", \"latest-small\", \"100k\", \"1m\", \"20m\". In all of the datasets, the movies and ratings data are joined on \"movieId\". The 25m dataset, latest-small dataset, and 20m dataset contain only the movie and rating data. The 1m dataset and 100k dataset contain demographic data in addition to the movie and rating data.\n",
    "\n",
    "\n",
    "**[movie_lens/100k-ratings](https://www.tensorflow.org/datasets/catalog/movie_lens#movie_lens100k-ratings):**\n",
    " * Config description: This dataset contains 100,000 anonymous ratings of approximately 1,682 movies made by 943 MovieLens users who joined MovieLens. Ratings are in whole-star increments. This dataset contains demographic data of users in addition to data on movies and ratings.\n",
    " \n",
    " * This dataset is the second largest dataset that includes demographic data from movie_lens.\n",
    " * \"user_gender\": gender of the user who made the rating; a true value corresponds to male.\n",
    " * \"bucketized_user_age\": bucketized age values of the user who made the rating, the values and the corresponding ranges are:\n",
    "   * 1: \"Under 18\"\n",
    "   * 18: \"18-24\"\n",
    "   * 25: \"25-34\"\n",
    "   * 35: \"35-44\"\n",
    "   * 45: \"45-49\"\n",
    "   * 50: \"50-55\"\n",
    "   * 56: \"56+\"\n",
    " * \"movie_genres\": The Genres of the movies are classified into 21 different classes as below:\n",
    "   * 0: Action\n",
    "   * 1: Adventure\n",
    "   * 2: Animation\n",
    "   * 3: Children\n",
    "   * 4: Comedy\n",
    "   * 5: Crime\n",
    "   * 6: Documentary\n",
    "   * 7: Drama\n",
    "   * 8: Fantasy\n",
    "   * 9: Film-Noir\n",
    "   * 10: Horror\n",
    "   * 11: IMAX\n",
    "   * 12: Musical\n",
    "   * 13: Mystery\n",
    "   * 14: Romance\n",
    "   * 15: Sci-Fi\n",
    "   * 16: Thriller\n",
    "   * 17: Unknown\n",
    "   * 18: War\n",
    "   * 19: Western\n",
    "   * 20: no genres listed\n",
    "   \n",
    " * \"user_occupation_label\": the occupation of the user who made the rating represented by an integer-encoded label; labels are preprocessed to be consistent across different versions\n",
    " * \"user_occupation_text\": the occupation of the user who made the rating in the original string; different versions can have different set of raw text labels\n",
    " * \"user_zip_code\": the zip code of the user who made the rating.\n",
    " * Download size: 4.70 MiB\n",
    " * Dataset size: 32.41 MiB\n",
    " * Auto-cached ([documentation](https://www.tensorflow.org/datasets/performances#auto-caching)): No\n",
    " * Features:\n",
    " ```\n",
    " FeaturesDict({\n",
    "               'bucketized_user_age': tf.float32,\n",
    "               'movie_genres': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=21)),\n",
    "               'movie_id': tf.string,\n",
    "               'movie_title': tf.string,\n",
    "               'raw_user_age': tf.float32,\n",
    "               'timestamp': tf.int64,\n",
    "               'user_gender': tf.bool,\n",
    "               'user_id': tf.string,\n",
    "               'user_occupation_label': ClassLabel(shape=(), dtype=tf.int64, num_classes=22),\n",
    "               'user_occupation_text': tf.string,\n",
    "               'user_rating': tf.float32,\n",
    "               'user_zip_code': tf.string,\n",
    "              })\n",
    " ```\n",
    "**Example:**\n",
    "\n",
    "|bucketized_user_age\t|movie_genres|\tmovie_id|\tmovie_title|\traw_user_age|\ttimestamp|\tuser_gender|\tuser_id\t|user_occupation_label|\tuser_occupation_text\t|user_rating\t|user_zip_code|\n",
    "|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|\n",
    "|45.0\t|7 (Drama)|b'357'\t|b\"One Flew Over the Cuckoo's Nest (1975)\"\t|46.0\t|879024327\t|True\t|b'138'\t|4 (doctor/health care)\t|b'doctor'\t|4.0|\tb'53211'|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d9d46e-62fe-4676-8bb9-2abf9e64747c",
   "metadata": {},
   "source": [
    "### Preparing the datasets\n",
    "\n",
    "Let's have a first look at the data.\n",
    "\n",
    "We use the MovieLens dataset from Tensorflow Datasets. Loading **[movie_lens/100k-ratings](https://www.tensorflow.org/datasets/catalog/movie_lens#movie_lens100k-ratings)** yields a ***tf.data.Dataset*** object containing the ratings data and loading **[movie_lens/100k-movies](https://www.tensorflow.org/datasets/catalog/movie_lens#movie_lens100k-movies)** yields a ***tf.data.Dataset*** object containing only the movies data.\n",
    "\n",
    "Note that since the MovieLens dataset does not have predefined splits, all data are under train split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e135fd-3715-4620-ade0-19e239ebf99f",
   "metadata": {},
   "source": [
    "### Features Importance Using Deep & Cross Network (DCN-V2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa256707-a47a-40eb-82ea-8373194ff3c8",
   "metadata": {},
   "source": [
    "**Deep and cross network (DCN) came out of Google Research, and is designed to learn explicit and bounded-degree cross features effectively**\n",
    "\n",
    "- Large and sparse feature space is extremely hard to train.\n",
    "- Oftentimes, we needed to do a lot of manual feature engineering, including designing cross features, which is very challenging and less effective.\n",
    "- Whilst possible to use additional neural networks under such circumstances, it's not the most efficient approach. DCN is specifically designed to tackle all of the above challenges.\n",
    "\n",
    "**Feature Cross**\n",
    "\n",
    "Let's say we're building a recommender system to sell a blender to customers. Then our customers' past purchase history, such as purchased apples and purchased recipes books, or geographic features are single features. If one has purchased both apples and recipes books, then this customer will be more likely to click on the recommended blender. The combination of purchased apples and the purchased recipes books is referred to as feature cross, which provides additional interaction information beyond the individual features.\n",
    "\n",
    "**Cross Network**\n",
    "\n",
    "In real world recommendation systems, we often have large and sparse feature space. So, identifying effective feature processes in this setting would often require manual feature engineering or exhaustive search, which is highly inefficient. To tackle this issue, Google Research team has proposed DCN. It starts with an input layer, typically an embedded layer, followed by a cross network containing multiple cross layers that models explicitly feature interactions, and then combines with a deep network that models implicit feature interactions. The deep network is just a traditional multilayer construction. But the core of DCN is really the cross network. It explicitly applies feature crossing at each layer. And the highest polynomial degree increases with layer depth.\n",
    "\n",
    "**Deep & Cross Network**\n",
    "\n",
    "There are a couple of ways to combine the cross network and the deep network:\n",
    "\n",
    "- Stack the deep network on top of the cross network.\n",
    "- Place deep & cross networks in parallel.\n",
    "\n",
    "**Model Structure**\n",
    "\n",
    "We first train a DCN model with a stacked structure, that is, the inputs are fed to a cross network followed by a deep network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9b8ca69f-bd1d-4156-8f08-362d1f3dbef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\mohamed.ziane\\\\tensorflow_datasets\\\\Notebooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "54ff1e2b-8e0a-44c4-9d10-4b28047c8967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's look at the final dataframe where we merged the tensorflow dataset with movies_metadata.csv and credits.csv**\n",
    "\n",
    "ratings = pd.read_csv('ratings.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "094634e9-2507-44ab-a7b8-b71f24c45659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucketized_user_age</th>\n",
       "      <th>movie_genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_occupation_label</th>\n",
       "      <th>user_occupation_text</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>user_zip_code</th>\n",
       "      <th>director</th>\n",
       "      <th>release_date</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>[7]</td>\n",
       "      <td>357</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>879024327</td>\n",
       "      <td>True</td>\n",
       "      <td>138</td>\n",
       "      <td>4</td>\n",
       "      <td>doctor</td>\n",
       "      <td>4</td>\n",
       "      <td>53211</td>\n",
       "      <td>Milos Forman</td>\n",
       "      <td>185500800</td>\n",
       "      <td>Jack Nicholson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>[4, 14]</td>\n",
       "      <td>709</td>\n",
       "      <td>Strictly Ballroom</td>\n",
       "      <td>875654590</td>\n",
       "      <td>True</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>2</td>\n",
       "      <td>80525</td>\n",
       "      <td>Baz Luhrmann</td>\n",
       "      <td>714268800</td>\n",
       "      <td>Paul Mercurio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>[5, 7]</td>\n",
       "      <td>56</td>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>883326919</td>\n",
       "      <td>True</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>4</td>\n",
       "      <td>6472</td>\n",
       "      <td>Quentin Tarantino</td>\n",
       "      <td>779155200</td>\n",
       "      <td>John Travolta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>[10, 16]</td>\n",
       "      <td>895</td>\n",
       "      <td>Scream 2</td>\n",
       "      <td>891409199</td>\n",
       "      <td>True</td>\n",
       "      <td>197</td>\n",
       "      <td>18</td>\n",
       "      <td>technician</td>\n",
       "      <td>3</td>\n",
       "      <td>75094</td>\n",
       "      <td>Wes Craven</td>\n",
       "      <td>881625600</td>\n",
       "      <td>David Arquette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>[7, 16]</td>\n",
       "      <td>325</td>\n",
       "      <td>Crash</td>\n",
       "      <td>876346551</td>\n",
       "      <td>False</td>\n",
       "      <td>601</td>\n",
       "      <td>1</td>\n",
       "      <td>artist</td>\n",
       "      <td>4</td>\n",
       "      <td>99687</td>\n",
       "      <td>David Cronenberg</td>\n",
       "      <td>837561600</td>\n",
       "      <td>James Spader</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bucketized_user_age movie_genres  movie_id  \\\n",
       "0                   45          [7]       357   \n",
       "1                   25      [4, 14]       709   \n",
       "2                   50       [5, 7]        56   \n",
       "3                   50     [10, 16]       895   \n",
       "4                   18      [7, 16]       325   \n",
       "\n",
       "                       movie_title  timestamp  user_gender  user_id  \\\n",
       "0  One Flew Over the Cuckoo's Nest  879024327         True      138   \n",
       "1                Strictly Ballroom  875654590         True       92   \n",
       "2                     Pulp Fiction  883326919         True       60   \n",
       "3                         Scream 2  891409199         True      197   \n",
       "4                            Crash  876346551        False      601   \n",
       "\n",
       "   user_occupation_label user_occupation_text  user_rating  user_zip_code  \\\n",
       "0                      4               doctor            4          53211   \n",
       "1                      5        entertainment            2          80525   \n",
       "2                      4           healthcare            4           6472   \n",
       "3                     18           technician            3          75094   \n",
       "4                      1               artist            4          99687   \n",
       "\n",
       "            director  release_date            star  \n",
       "0       Milos Forman     185500800  Jack Nicholson  \n",
       "1       Baz Luhrmann     714268800   Paul Mercurio  \n",
       "2  Quentin Tarantino     779155200   John Travolta  \n",
       "3         Wes Craven     881625600  David Arquette  \n",
       "4   David Cronenberg     837561600    James Spader  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 88649 entries, 0 to 88648\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   bucketized_user_age    88649 non-null  int64 \n",
      " 1   movie_genres           88649 non-null  object\n",
      " 2   movie_id               88649 non-null  int64 \n",
      " 3   movie_title            88649 non-null  object\n",
      " 4   timestamp              88649 non-null  int64 \n",
      " 5   user_gender            88649 non-null  bool  \n",
      " 6   user_id                88649 non-null  int64 \n",
      " 7   user_occupation_label  88649 non-null  int64 \n",
      " 8   user_occupation_text   88649 non-null  object\n",
      " 9   user_rating            88649 non-null  int64 \n",
      " 10  user_zip_code          88649 non-null  int64 \n",
      " 11  director               88649 non-null  object\n",
      " 12  release_date           88649 non-null  int64 \n",
      " 13  star                   88649 non-null  object\n",
      "dtypes: bool(1), int64(8), object(5)\n",
      "memory usage: 8.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# now let's look at the the table:\n",
    "\n",
    "ratings.head()\n",
    "ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "eba07cbc-20b3-456a-8c2e-f16ae831770d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>data_type</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bucketized_user_age</th>\n",
       "      <td>7</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_genres</th>\n",
       "      <td>179</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <td>1117</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_title</th>\n",
       "      <td>1099</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <td>40530</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_gender</th>\n",
       "      <td>2</td>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>925</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_occupation_label</th>\n",
       "      <td>17</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_occupation_text</th>\n",
       "      <td>21</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_rating</th>\n",
       "      <td>5</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_zip_code</th>\n",
       "      <td>778</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director</th>\n",
       "      <td>976</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>release_date</th>\n",
       "      <td>995</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star</th>\n",
       "      <td>915</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count data_type missing_count missing%\n",
       "bucketized_user_age        7     int64             0      0.0\n",
       "movie_genres             179    object             0      0.0\n",
       "movie_id                1117    object             0      0.0\n",
       "movie_title             1099    object             0      0.0\n",
       "timestamp              40530     int64             0      0.0\n",
       "user_gender                2      bool             0      0.0\n",
       "user_id                  925    object             0      0.0\n",
       "user_occupation_label     17     int64             0      0.0\n",
       "user_occupation_text      21    object             0      0.0\n",
       "user_rating                5     int64             0      0.0\n",
       "user_zip_code            778    object             0      0.0\n",
       "director                 976    object             0      0.0\n",
       "release_date             995     int64             0      0.0\n",
       "star                     915    object             0      0.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# movie_id from int to str:\n",
    "ratings['movie_id'] = ratings['movie_id'].astype('str')\n",
    "\n",
    "# user_id from int to str:\n",
    "ratings['user_id'] = ratings['user_id'].astype('str')\n",
    "\n",
    "# user_zip_code from int to str:\n",
    "ratings['user_zip_code'] = ratings['user_zip_code'].astype('str')\n",
    "\n",
    "#let's have a general view:\n",
    "ratings_missing = pd.concat([ratings.nunique(), ratings.dtypes, ratings.isnull().sum(), 100*ratings.isnull().mean()], axis=1)\n",
    "ratings_missing.columns = [['count', 'data_type', 'missing_count', 'missing%']]\n",
    "ratings_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0a131206-df6d-443d-8878-571fe41ae6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's wrap the **pandas dataframe** into **tf.data.Dataset** object using **tf.data.Dataset.from_tensor_slices** using: tf.data.Dataset.from_tensor_slices\n",
    "ratings = tf.data.Dataset.from_tensor_slices(dict(ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "70ef3063-7507-4d5d-9d44-90fa3a69fb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': 45,\n",
      " 'director': b'Milos Forman',\n",
      " 'movie_genres': b'[7]',\n",
      " 'movie_id': b'357',\n",
      " 'movie_title': b\"One Flew Over the Cuckoo's Nest\",\n",
      " 'release_date': 185500800,\n",
      " 'star': b'Jack Nicholson',\n",
      " 'timestamp': 879024327,\n",
      " 'user_gender': True,\n",
      " 'user_id': b'138',\n",
      " 'user_occupation_label': 4,\n",
      " 'user_occupation_text': b'doctor',\n",
      " 'user_rating': 4,\n",
      " 'user_zip_code': b'53211'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The ratings dataset returns a dictionary of movie id, user id, the assigned rating, timestamp, movie information, and user information:\n",
    "#View the data from ratings dataset:\n",
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)\n",
    "    \n",
    "type(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae01a9e9-f82c-46a4-aab7-5918eb28549b",
   "metadata": {},
   "source": [
    "**Next, we're only going to extract the movie title and the user id.**\n",
    "\n",
    "- We are actually not going to extract the rating itself and the reason why is that we're treating these as implicit recommendations.\n",
    "- We are going to assume that any movie that a user rated is one that they were really interested in if they took the time to watch it and it therefore expresses some level of interest.\n",
    "\n",
    "*That being said, any rating is an implicit positive rating for a movie and the absence of a rating is an implicit negative rating for that movie.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eddfba3c-6fe9-4c74-8e8d-bcfd98ab2fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88649"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's select the necessary attributes:\n",
    "\n",
    "ratings = ratings.map(lambda x: {\n",
    "                                 \"movie_id\": x[\"movie_id\"],\n",
    "                                 \"user_id\": x[\"user_id\"],\n",
    "                                 \"user_rating\": x[\"user_rating\"],\n",
    "                                 \"user_gender\": int(x[\"user_gender\"]),\n",
    "                                 \"user_zip_code\": x[\"user_zip_code\"],\n",
    "                                 \"user_occupation_text\": x[\"user_occupation_text\"],\n",
    "                                 \"director\": x[\"director\"],\n",
    "                                 \"star\": x[\"star\"],\n",
    "                                 \"movie_genres\": x[\"movie_genres\"],    \n",
    "                                 \"bucketized_user_age\": int(x[\"bucketized_user_age\"]),                                \n",
    "                                })\n",
    "\n",
    "len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9bf9a429-7235-478b-914a-c46c2b856d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88649"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's select the necessary attributes:\n",
    "\n",
    "ratings = ratings.map(lambda x: {\n",
    "                                 \"movie_id\": x[\"movie_id\"],\n",
    "                                 \"user_id\": x[\"user_id\"],\n",
    "                                 \"user_rating\": x[\"user_rating\"],\n",
    "                                 \"user_gender\": int(x[\"user_gender\"]),\n",
    "                                 \"user_zip_code\": x[\"user_zip_code\"],\n",
    "                                 \"user_occupation_text\": x[\"user_occupation_text\"],\n",
    "                                 \"director\": x[\"director\"],\n",
    "                                 \"star\": x[\"star\"],\n",
    "                                 \"movie_genres\": x[\"movie_genres\"],    \n",
    "                                 \"bucketized_user_age\": int(x[\"bucketized_user_age\"]),                                \n",
    "                                })\n",
    "\n",
    "len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f823a311-127b-4171-93cd-78a0a46490ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use a random split, putting 75% of the ratings in the train set, and 25% in the test set:\n",
    "# Assign a seed=42 for consistency of results and reproducibility:\n",
    "seed = 42\n",
    "l = len(ratings)\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "shuffled = ratings.shuffle(l, seed=seed, reshuffle_each_iteration=False)\n",
    "\n",
    "#Save 75% of the data for training and 25% for testing:\n",
    "train_ = int(0.75 * l)\n",
    "test_ = int(0.25 * l)\n",
    "\n",
    "train = shuffled.take(train_)\n",
    "test = shuffled.skip(train_).take(test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f82f19b7-edfb-480b-9039-66104d49ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then, let's create a vocabulary for each feature:\n",
    "\n",
    "feature_names = [\"movie_id\", \"user_id\", \"user_gender\", \"user_zip_code\",\n",
    "                 \"user_occupation_text\", \"bucketized_user_age\", \"director\", \"star\"]\n",
    "\n",
    "vocabularies = {}\n",
    "\n",
    "for feature_name in feature_names:\n",
    "    vocab = ratings.batch(l).map(lambda x: x[feature_name])\n",
    "    vocabularies[feature_name] = np.unique(np.concatenate(list(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bc9a87-00f0-4198-8d7f-0870796a09f1",
   "metadata": {},
   "source": [
    "### Model construction\n",
    "- The model architecture we will be building starts with an embedded layer, which is fed into a cross network followed by a deep network. \n",
    "- The embedded dimension is set to 32 for all the features. \n",
    "- Please note that we could also have used different embedded sizes for different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8a8480e7-29b0-449a-9253-e94b3b6f4766",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCN(tfrs.Model):\n",
    "    def __init__(self, use_cross_layer, deep_layer_sizes, projection_dim=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_dimension = 32\n",
    "\n",
    "        str_features = [\"movie_id\", \"user_id\", \"user_zip_code\", \n",
    "                        \"user_occupation_text\", \"director\", \"star\"]\n",
    "        int_features = [\"user_gender\", \"bucketized_user_age\"]\n",
    "\n",
    "        self._all_features = str_features + int_features\n",
    "        self._embeddings = {}\n",
    "\n",
    "        # Compute embeddings for string features. experimental.preprocessing\n",
    "        # WARNING:tensorflow:mask_value is deprecated, use mask_token instead.\n",
    "        for feature_name in str_features:\n",
    "            vocabulary = vocabularies[feature_name]\n",
    "            self._embeddings[feature_name] = tf.keras.Sequential(\n",
    "                                                                [tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                                                                 vocabulary=vocabulary, mask_token=None),\n",
    "                                                                 tf.keras.layers.Embedding(len(vocabulary) + 1,\n",
    "                                                                 self.embedding_dimension)\n",
    "                                           ])\n",
    "      \n",
    "        # Compute embeddings for int features.\n",
    "        for feature_name in int_features:\n",
    "            vocabulary = vocabularies[feature_name]\n",
    "            self._embeddings[feature_name] = tf.keras.Sequential(\n",
    "                                                                 [tf.keras.layers.experimental.preprocessing.IntegerLookup(\n",
    "                                                                 vocabulary=vocabulary, mask_token=None), \n",
    "                                                                 tf.keras.layers.Embedding(len(vocabulary) + 1,\n",
    "                                                                 self.embedding_dimension)\n",
    "                                           ])\n",
    "\n",
    "        if use_cross_layer:\n",
    "            self._cross_layer = tfrs.layers.dcn.Cross(\n",
    "                                                      projection_dim=projection_dim,\n",
    "                                                      kernel_initializer=\"glorot_uniform\")\n",
    "        else:\n",
    "            self._cross_layer = None\n",
    "\n",
    "        self._deep_layers = [tf.keras.layers.Dense(layer_size, activation=\"relu\")\n",
    "            for layer_size in deep_layer_sizes]\n",
    "\n",
    "        self._logit_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "        self.task = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError(\"RMSE\")]\n",
    "            )\n",
    "\n",
    "    def call(self, features):\n",
    "        # Concatenate embeddings\n",
    "        embeddings = []\n",
    "        for feature_name in self._all_features:\n",
    "            embedding_fn = self._embeddings[feature_name]\n",
    "            embeddings.append(embedding_fn(features[feature_name]))\n",
    "\n",
    "        x = tf.concat(embeddings, axis=1)\n",
    "\n",
    "        # Build Cross Network\n",
    "        if self._cross_layer is not None:\n",
    "            x = self._cross_layer(x)\n",
    "    \n",
    "    # Build Deep Network\n",
    "        for deep_layer in self._deep_layers:\n",
    "            x = deep_layer(x)\n",
    "\n",
    "        return self._logit_layer(x)\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        labels = features.pop(\"user_rating\")\n",
    "        scores = self(features)\n",
    "        return self.task(labels=labels,predictions=scores,\n",
    "        )        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db76b76-ef5e-46f6-89ad-6cacd469c926",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7b3cc8ba-2774-4e2d-8e83-4445602f8de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling, batching, and caching the training and evaluatiing the data:\n",
    "# Segmenting the batches so that the model runs 13 training batches (2^13) and 11 test batches (2^11) per epoch, \n",
    "# while having a batch size which is a multiple of 2^n.\n",
    "\n",
    "cached_train = train.shuffle(l).batch(8192).cache()\n",
    "cached_test = test.batch(2048).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8f14c76a-e6d3-4e29-8e51-7ed2f4cbbcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's define a function that runs a model multiple times and returns the model's RMSE mean and standard deviation out of multiple runs\n",
    "\n",
    "def run_models(use_cross_layer, deep_layer_sizes, projection_dim=None, num_runs=5):\n",
    "    models = []\n",
    "    rmses = []\n",
    "\n",
    "    for i in range(num_runs):\n",
    "        model = DCN(use_cross_layer=use_cross_layer,\n",
    "                    deep_layer_sizes=deep_layer_sizes,\n",
    "                    projection_dim=projection_dim)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate))\n",
    "        models.append(model)\n",
    "\n",
    "        model.fit(cached_train, epochs=epochs, verbose=False)\n",
    "        metrics = model.evaluate(cached_test, return_dict=True)\n",
    "        rmses.append(metrics[\"RMSE\"])\n",
    "\n",
    "    mean, stdv = np.average(rmses), np.std(rmses)\n",
    "\n",
    "    return {\"model\": models, \"mean\": mean, \"stdv\": stdv}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f0fa15-da6e-433e-83b0-9aa114c04bcb",
   "metadata": {},
   "source": [
    "We set some hyper-parameters for the models. \n",
    "\n",
    "- Note that these hyper-parameters are set globally for all the models for demonstration purpose. \n",
    "\n",
    "- If you want to obtain the best performance for each model, or to conduct a fair comparison amongst models, I would suggest you to fine-tune the hyper-parameters. \n",
    "\n",
    "- Remember that the model architecture and optimization schemes are intertwined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "22b0cdee-4553-4d6f-a53b-f51c866916c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 32\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9c9079-1a2f-4a2e-bd0b-fdcc93ab1498",
   "metadata": {},
   "source": [
    "### DCN (stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cbe646ed-b645-432a-86f7-f313b95f5056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 2s 22ms/step - RMSE: 0.9840 - loss: 0.9661 - regularization_loss: 0.0000e+00 - total_loss: 0.9661\n",
      "11/11 [==============================] - 0s 8ms/step - RMSE: 1.0097 - loss: 1.0228 - regularization_loss: 0.0000e+00 - total_loss: 1.0228\n",
      "11/11 [==============================] - 0s 8ms/step - RMSE: 0.9365 - loss: 0.8768 - regularization_loss: 0.0000e+00 - total_loss: 0.8768\n",
      "11/11 [==============================] - 0s 7ms/step - RMSE: 0.9881 - loss: 0.9719 - regularization_loss: 0.0000e+00 - total_loss: 0.9719\n",
      "11/11 [==============================] - 0s 8ms/step - RMSE: 0.9872 - loss: 0.9718 - regularization_loss: 0.0000e+00 - total_loss: 0.9718\n"
     ]
    }
   ],
   "source": [
    "#We first train a DCN model with a stacked structure, that is, the inputs are fed to a cross network followed by a deep network.\n",
    "\n",
    "dcn_result = run_models(use_cross_layer=True, deep_layer_sizes=[192, 192])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fa8dd6b1-4688-483d-9dae-be3779d0d368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1fb7f0fd5e0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing the Weight Matrix Learned by DCN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "model = dcn_result[\"model\"][0]\n",
    "mat = model._cross_layer._dense.kernel\n",
    "features = model._all_features\n",
    "\n",
    "block_norm = np.ones([len(features), len(features)])\n",
    "dim = model.embedding_dimension\n",
    "\n",
    "# Compute the norms of the blocks.\n",
    "for i in range(len(features)):\n",
    "    for j in range(len(features)):\n",
    "        block = mat[i * dim:(i + 1) * dim,\n",
    "                j * dim:(j + 1) * dim]\n",
    "        block_norm[i,j] = np.linalg.norm(block, ord=\"fro\")\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "im = plt.matshow(block_norm, cmap=plt.cm.Blues)\n",
    "ax = plt.gca()\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "plt.colorbar(im, cax=cax)\n",
    "cax.tick_params(labelsize=10) \n",
    "_ = ax.set_xticklabels([\"\"] + features, rotation=45, ha=\"left\", fontsize=10)\n",
    "_ = ax.set_yticklabels([\"\"] + features, fontsize=10)\n",
    "#plt.title('Visualizing the Weight Matrix Learned by DCN')\n",
    "print('Visualizing the Weight Matrix Learned by DCN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34e80f1-65fe-4e01-8041-8c876a128077",
   "metadata": {},
   "source": [
    "From the above graph, we can visualize the weights from the cross network and see if it has successfully learned the important feature process. \n",
    "\n",
    "As shown above, fro instance, the feature cross of user ID and movie ID are of great importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19cc5aa-9b87-4599-bd52-06e2a8ceec65",
   "metadata": {},
   "source": [
    "### Low-rank DCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044ccbf5-6018-4c9c-a4c0-e0107befe8a8",
   "metadata": {},
   "source": [
    "To reduce the training and running cost, we leverage low-rank techniques to approximate the DCN weight matrices. \n",
    "\n",
    "- The rank is passed in through the projection_dim argument: a smaller projection_dim results in a lower cost. \n",
    "\n",
    "- Note that projection_dim needs to be smaller than the (input size)/2 to reduce the cost. In practice, we've observed that using a low-rank DCN with a rank of (input size)/4 consistently preserved the accuracy of a full-rank DCN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e7d4780e-b1ab-44e2-92a9-5b82659da88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 7ms/step - RMSE: 0.9584 - loss: 0.9179 - regularization_loss: 0.0000e+00 - total_loss: 0.9179\n",
      "11/11 [==============================] - 0s 7ms/step - RMSE: 0.9627 - loss: 0.9267 - regularization_loss: 0.0000e+00 - total_loss: 0.9267\n",
      "11/11 [==============================] - 0s 6ms/step - RMSE: 0.9787 - loss: 0.9578 - regularization_loss: 0.0000e+00 - total_loss: 0.9578\n",
      "11/11 [==============================] - 0s 9ms/step - RMSE: 0.9838 - loss: 0.9629 - regularization_loss: 0.0000e+00 - total_loss: 0.9629\n",
      "11/11 [==============================] - 0s 7ms/step - RMSE: 0.9496 - loss: 0.9042 - regularization_loss: 0.0000e+00 - total_loss: 0.9042\n"
     ]
    }
   ],
   "source": [
    "dcn_lr_result = run_models(use_cross_layer=True,\n",
    "                           projection_dim=20,\n",
    "                           deep_layer_sizes=[192, 192])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51c9c12-9d0f-4142-b9a3-4ce2d33637a7",
   "metadata": {},
   "source": [
    "### DNN (Cross Layer = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6588aaff-aa54-4eaf-8245-2155fe236985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 7ms/step - RMSE: 0.9388 - loss: 0.8795 - regularization_loss: 0.0000e+00 - total_loss: 0.8795\n",
      "11/11 [==============================] - 0s 7ms/step - RMSE: 0.9515 - loss: 0.9034 - regularization_loss: 0.0000e+00 - total_loss: 0.9034\n",
      "11/11 [==============================] - 0s 8ms/step - RMSE: 0.9736 - loss: 0.9478 - regularization_loss: 0.0000e+00 - total_loss: 0.9478\n",
      "11/11 [==============================] - 0s 7ms/step - RMSE: 0.9537 - loss: 0.9108 - regularization_loss: 0.0000e+00 - total_loss: 0.9108\n",
      "11/11 [==============================] - 0s 7ms/step - RMSE: 0.9479 - loss: 0.8995 - regularization_loss: 0.0000e+00 - total_loss: 0.8995\n"
     ]
    }
   ],
   "source": [
    "# We train a same-sized DNN model as a reference.\n",
    "dnn_result = run_models(use_cross_layer=False,\n",
    "                        deep_layer_sizes=[192, 192, 192])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ca926a7a-81f8-43f4-9571-5dd5bc440fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCN            RMSE mean: 0.9811, stdv: 0.0241\n",
      "DCN (low-rank) RMSE mean: 0.9666, stdv: 0.0128\n",
      "DNN            RMSE mean: 0.9531, stdv: 0.0115\n"
     ]
    }
   ],
   "source": [
    "print(\"DCN            RMSE mean: {:.4f}, stdv: {:.4f}\".format(dcn_result[\"mean\"], dcn_result[\"stdv\"]))\n",
    "print(\"DCN (low-rank) RMSE mean: {:.4f}, stdv: {:.4f}\".format(dcn_lr_result[\"mean\"], dcn_lr_result[\"stdv\"]))\n",
    "print(\"DNN            RMSE mean: {:.4f}, stdv: {:.4f}\".format(dnn_result[\"mean\"], dnn_result[\"stdv\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d1d283-b53d-43f3-b0a5-916c72998934",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Multi-Task Model - Joint Model\n",
    "\n",
    "### The Two-Tower and Ranking Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dc032e-6048-416b-a9ae-a4bd2a21c6f6",
   "metadata": {},
   "source": [
    "**Real-world recommender systems are often composed of two stages:**\n",
    "\n",
    "- *The retrieval stage* (Selects recommendation candidates): is responsible for selecting an initial set of hundreds of candidates from all possible candidates. \n",
    "    - The main objective of this model is to efficiently weed out all candidates that the user is not interested in. Because the retrieval model may be dealing with millions of candidates, it has to be computationally efficient.\n",
    "\n",
    "- *The ranking stage* (Selects the best candidates and rank them): takes the outputs of the retrieval model and fine-tunes them to select the best possible handful of recommendations. \n",
    "    - Its task is to narrow down the set of items the user may be interested in to a shortlist of likely candidates.\n",
    "\n",
    "**Retrieval models are often composed of two sub-models:**\n",
    "\n",
    "The retrieval model embeds user ID's and movie ID's of rated movies into embedded layers of the same dimension:\n",
    "\n",
    "- A query model computing the query representation (normally a fixed-dimensionality embedding vector) using query features.\n",
    "\n",
    "- A candidate model computing the candidate representation (an equally-sized vector) using the candidate features.\n",
    "\n",
    "- As shown below, the two models are multiplied to create a query-candidate affinity scores for each rating during training. If the affinity score for the rating is higher than  other candidates, then we can consider the model to be reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ee5b4b-83e8-4cb0-ad1b-63ba8725a5b6",
   "metadata": {},
   "source": [
    "**Embedded layer Magic**\n",
    "\n",
    "As discussed above, we might think of the embedded layers as just a way of encoding a way of forcing the categorical data into some sort of a standard format that can be easily fed into a neural network and usually that's how it's used but embedded layers are more than that! \n",
    "\n",
    "The way they're working under the hood is every unique id is being mapped to a vector of n dimensions, but it's going to be like a vector of 32 floating point values and we can think of this as a position in a 32-dimensional space that represents the similarity between one user id and another or between one movie id and another so by using embeddied layers in this way we're getting around that whole problem of data sparsity and sparse vectors and at the same time, we're getting a measure of similarity  so it's a very simple way of getting recommendation candidates.\n",
    "\n",
    "The outputs of the two models are then multiplied together to give a query-candidate affinity score, with higher scores expressing a better match between the candidate and the query.\n",
    "\n",
    "In this Model, we built and trained such a two-tower model using the Movielens dataset (100k Dataset):\n",
    "\n",
    "- Getting our data and splitting it into a training and test set.\n",
    "- Implementing a retrieval model.\n",
    "- Fitting and evaluating it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f333173-b77a-4a66-a365-46b9264221ef",
   "metadata": {},
   "source": [
    "**The Ranking**\n",
    "\n",
    "The ranking stage takes the outputs of the retrieval model and fine-tunes them to select the best possible handful of recommendations. \n",
    "- Its task is to narrow down the set of items the user may be interested in to a shortlist of likely candidates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93830657-7459-4ffe-aeae-9a69292299e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Case 1: Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5d1627-cfb4-49b2-8ef3-348295e6e8ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Double-checking the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0978314c-2c04-4796-b4de-84e1b642ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings data.\n",
    "ratings = pd.read_csv('ratings.csv', encoding='ISO-8859-1')\n",
    "# Features of all the available movies.\n",
    "movies = pd.read_csv('df_movies.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "60cfb720-3759-4559-b13b-76cd80800356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucketized_user_age</th>\n",
       "      <th>movie_genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_occupation_label</th>\n",
       "      <th>user_occupation_text</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>user_zip_code</th>\n",
       "      <th>director</th>\n",
       "      <th>release_date</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>[7]</td>\n",
       "      <td>357</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>879024327</td>\n",
       "      <td>True</td>\n",
       "      <td>138</td>\n",
       "      <td>4</td>\n",
       "      <td>doctor</td>\n",
       "      <td>4</td>\n",
       "      <td>53211</td>\n",
       "      <td>Milos Forman</td>\n",
       "      <td>185500800</td>\n",
       "      <td>Jack Nicholson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>[4, 14]</td>\n",
       "      <td>709</td>\n",
       "      <td>Strictly Ballroom</td>\n",
       "      <td>875654590</td>\n",
       "      <td>True</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>2</td>\n",
       "      <td>80525</td>\n",
       "      <td>Baz Luhrmann</td>\n",
       "      <td>714268800</td>\n",
       "      <td>Paul Mercurio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>[5, 7]</td>\n",
       "      <td>56</td>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>883326919</td>\n",
       "      <td>True</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>4</td>\n",
       "      <td>6472</td>\n",
       "      <td>Quentin Tarantino</td>\n",
       "      <td>779155200</td>\n",
       "      <td>John Travolta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>[10, 16]</td>\n",
       "      <td>895</td>\n",
       "      <td>Scream 2</td>\n",
       "      <td>891409199</td>\n",
       "      <td>True</td>\n",
       "      <td>197</td>\n",
       "      <td>18</td>\n",
       "      <td>technician</td>\n",
       "      <td>3</td>\n",
       "      <td>75094</td>\n",
       "      <td>Wes Craven</td>\n",
       "      <td>881625600</td>\n",
       "      <td>David Arquette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>[7, 16]</td>\n",
       "      <td>325</td>\n",
       "      <td>Crash</td>\n",
       "      <td>876346551</td>\n",
       "      <td>False</td>\n",
       "      <td>601</td>\n",
       "      <td>1</td>\n",
       "      <td>artist</td>\n",
       "      <td>4</td>\n",
       "      <td>99687</td>\n",
       "      <td>David Cronenberg</td>\n",
       "      <td>837561600</td>\n",
       "      <td>James Spader</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bucketized_user_age movie_genres  movie_id  \\\n",
       "0                   45          [7]       357   \n",
       "1                   25      [4, 14]       709   \n",
       "2                   50       [5, 7]        56   \n",
       "3                   50     [10, 16]       895   \n",
       "4                   18      [7, 16]       325   \n",
       "\n",
       "                       movie_title  timestamp  user_gender  user_id  \\\n",
       "0  One Flew Over the Cuckoo's Nest  879024327         True      138   \n",
       "1                Strictly Ballroom  875654590         True       92   \n",
       "2                     Pulp Fiction  883326919         True       60   \n",
       "3                         Scream 2  891409199         True      197   \n",
       "4                            Crash  876346551        False      601   \n",
       "\n",
       "   user_occupation_label user_occupation_text  user_rating  user_zip_code  \\\n",
       "0                      4               doctor            4          53211   \n",
       "1                      5        entertainment            2          80525   \n",
       "2                      4           healthcare            4           6472   \n",
       "3                     18           technician            3          75094   \n",
       "4                      1               artist            4          99687   \n",
       "\n",
       "            director  release_date            star  \n",
       "0       Milos Forman     185500800  Jack Nicholson  \n",
       "1       Baz Luhrmann     714268800   Paul Mercurio  \n",
       "2  Quentin Tarantino     779155200   John Travolta  \n",
       "3         Wes Craven     881625600  David Arquette  \n",
       "4   David Cronenberg     837561600    James Spader  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 88649 entries, 0 to 88648\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   bucketized_user_age    88649 non-null  int64 \n",
      " 1   movie_genres           88649 non-null  object\n",
      " 2   movie_id               88649 non-null  int64 \n",
      " 3   movie_title            88649 non-null  object\n",
      " 4   timestamp              88649 non-null  int64 \n",
      " 5   user_gender            88649 non-null  bool  \n",
      " 6   user_id                88649 non-null  int64 \n",
      " 7   user_occupation_label  88649 non-null  int64 \n",
      " 8   user_occupation_text   88649 non-null  object\n",
      " 9   user_rating            88649 non-null  int64 \n",
      " 10  user_zip_code          88649 non-null  int64 \n",
      " 11  director               88649 non-null  object\n",
      " 12  release_date           88649 non-null  int64 \n",
      " 13  star                   88649 non-null  object\n",
      "dtypes: bool(1), int64(8), object(5)\n",
      "memory usage: 8.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(88649, 14)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General Information\n",
    "ratings.head()\n",
    "ratings.info()\n",
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2631ce5-4a92-4bb1-bb5b-75617f365802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4]</td>\n",
       "      <td>b'1681'</td>\n",
       "      <td>b'You So Crazy (1994)'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4 7]</td>\n",
       "      <td>b'1457'</td>\n",
       "      <td>b'Love Is All There Is (1996)'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1 3]</td>\n",
       "      <td>b'500'</td>\n",
       "      <td>b'Fly Away Home (1996)'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0]</td>\n",
       "      <td>b'838'</td>\n",
       "      <td>b'In the Line of Duty 2 (1987)'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[7]</td>\n",
       "      <td>b'1648'</td>\n",
       "      <td>b'Niagara, Niagara (1997)'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_genres movie_id                      movie_title\n",
       "0          [4]  b'1681'           b'You So Crazy (1994)'\n",
       "1        [4 7]  b'1457'   b'Love Is All There Is (1996)'\n",
       "2        [1 3]   b'500'          b'Fly Away Home (1996)'\n",
       "3          [0]   b'838'  b'In the Line of Duty 2 (1987)'\n",
       "4          [7]  b'1648'       b'Niagara, Niagara (1997)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1682 entries, 0 to 1681\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   movie_genres  1682 non-null   object\n",
      " 1   movie_id      1682 non-null   object\n",
      " 2   movie_title   1682 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 39.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1682, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General Information\n",
    "movies.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "movies.head()\n",
    "movies.info()\n",
    "movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "516b7b46-90b2-4778-9d49-09cd5d5b99c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_id from int to str:\n",
    "ratings['movie_id'] = ratings['movie_id'].astype('str')\n",
    "\n",
    "# movie_id from int to str:\n",
    "movies['movie_id'] = movies['movie_id'].astype('str')\n",
    "\n",
    "# user_id from int to str:\n",
    "ratings['user_id'] = ratings['user_id'].astype('str')\n",
    "\n",
    "# user_zip_code from int to str:\n",
    "ratings['user_zip_code'] = ratings['user_zip_code'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9f31a08-a73d-49c4-830d-547a85f273d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>data_type</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bucketized_user_age</th>\n",
       "      <td>7</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_genres</th>\n",
       "      <td>179</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <td>1117</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_title</th>\n",
       "      <td>1099</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <td>40530</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_gender</th>\n",
       "      <td>2</td>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>925</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_occupation_label</th>\n",
       "      <td>17</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_occupation_text</th>\n",
       "      <td>21</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_rating</th>\n",
       "      <td>5</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_zip_code</th>\n",
       "      <td>778</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director</th>\n",
       "      <td>976</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>release_date</th>\n",
       "      <td>995</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star</th>\n",
       "      <td>915</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count data_type missing_count missing%\n",
       "bucketized_user_age        7     int64             0      0.0\n",
       "movie_genres             179    object             0      0.0\n",
       "movie_id                1117    object             0      0.0\n",
       "movie_title             1099    object             0      0.0\n",
       "timestamp              40530     int64             0      0.0\n",
       "user_gender                2      bool             0      0.0\n",
       "user_id                  925    object             0      0.0\n",
       "user_occupation_label     17     int64             0      0.0\n",
       "user_occupation_text      21    object             0      0.0\n",
       "user_rating                5     int64             0      0.0\n",
       "user_zip_code            778    object             0      0.0\n",
       "director                 976    object             0      0.0\n",
       "release_date             995     int64             0      0.0\n",
       "star                     915    object             0      0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's have a general view:\n",
    "ratings_missing = pd.concat([ratings.nunique(), ratings.dtypes, ratings.isnull().sum(), 100*ratings.isnull().mean()], axis=1)\n",
    "ratings_missing.columns = [['count', 'data_type', 'missing_count', 'missing%']]\n",
    "ratings_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2820e767-b355-4498-a1a6-f5bdd447e5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>data_type</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>movie_genres</th>\n",
       "      <td>216</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <td>1682</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_title</th>\n",
       "      <td>1664</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count data_type missing_count missing%\n",
       "movie_genres   216    object             0      0.0\n",
       "movie_id      1682    object             0      0.0\n",
       "movie_title   1664    object             0      0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's have a general view:\n",
    "movies_missing = pd.concat([movies.nunique(), movies.dtypes, movies.isnull().sum(), 100*movies.isnull().mean()], axis=1)\n",
    "movies_missing.columns = [['count', 'data_type', 'missing_count', 'missing%']]\n",
    "movies_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0af4b0c5-0428-4b91-9d1e-b12bb1609271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's wrap the **pandas dataframe** into **tf.data.Dataset** object using **tf.data.Dataset.from_tensor_slices** using: tf.data.Dataset.from_tensor_slices\n",
    "ratings = tf.data.Dataset.from_tensor_slices(dict(ratings))\n",
    "movies = tf.data.Dataset.from_tensor_slices(dict(movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02e2fd81-4a43-4f9c-a4b8-69e22cdc956f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': 45,\n",
      " 'director': b'Milos Forman',\n",
      " 'movie_genres': b'[7]',\n",
      " 'movie_id': b'357',\n",
      " 'movie_title': b\"One Flew Over the Cuckoo's Nest\",\n",
      " 'release_date': 185500800,\n",
      " 'star': b'Jack Nicholson',\n",
      " 'timestamp': 879024327,\n",
      " 'user_gender': True,\n",
      " 'user_id': b'138',\n",
      " 'user_occupation_label': 4,\n",
      " 'user_occupation_text': b'doctor',\n",
      " 'user_rating': 4,\n",
      " 'user_zip_code': b'53211'}\n"
     ]
    }
   ],
   "source": [
    "#The ratings dataset returns a dictionary of movie id, user id, the assigned rating, timestamp, movie information, and user information:\n",
    "#View the data from the ratings dataset:\n",
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfef7fa6-2cfa-494e-940a-7c0caf6dc304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': b'[4]',\n",
      " 'movie_id': b\"b'1681'\",\n",
      " 'movie_title': b\"b'You So Crazy (1994)'\"}\n"
     ]
    }
   ],
   "source": [
    "#The ratings dataset returns a dictionary of movie id, user id, the assigned rating, timestamp, movie information, and user information:\n",
    "#View the data from the movies dataset:\n",
    "for x in movies.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99f7827c-c762-4ae4-9fa3-ed6826daade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the basic features.\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": x[\"user_rating\"],\n",
    "})\n",
    "\n",
    "\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13c076ad-6899-4f8c-8e03-6c5c2fa0e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use a random split, putting 75% of the ratings in the train set, and 25% in the test set:\n",
    "# Assign a seed=42 for consistency of results and reproducibility:\n",
    "seed = 42\n",
    "l = len(ratings)\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "shuffled = ratings.shuffle(l, seed=seed, reshuffle_each_iteration=False)\n",
    "\n",
    "#Save 75% of the data for training and 25% for testing:\n",
    "train_ = int(0.75 * l)\n",
    "test_ = int(0.25 * l)\n",
    "\n",
    "train = shuffled.take(train_)\n",
    "test = shuffled.skip(train_).take(test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c44ef15d-2699-474b-bf24-ac74c1752e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'b\"\\'Til There Was You (1997)\"',\n",
       "       b'b\"Amityville 1992: It\\'s About Time (1992)\"',\n",
       "       b'b\"Antonia\\'s Line (1995)\"', b'b\"April Fool\\'s Day (1986)\"',\n",
       "       b'b\"Blood For Dracula (Andy Warhol\\'s Dracula) (1974)\"',\n",
       "       b'b\"Boy\\'s Life 2 (1997)\"', b'b\"Bram Stoker\\'s Dracula (1992)\"',\n",
       "       b'b\"Breakfast at Tiffany\\'s (1961)\"',\n",
       "       b'b\"Brother\\'s Kiss, A (1997)\"',\n",
       "       b'b\"C\\'est arriv\\\\xc3\\\\xa9 pr\\\\xc3\\\\xa8s de chez vous (1992)\"'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, let's find out how many uniques users/movies:\n",
    "movie_titles = movies.batch(l)\n",
    "user_ids = ratings.batch(l).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "#Movies uniques:\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "\n",
    "#users unique\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "# take a look at the movies:\n",
    "unique_movie_titles[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b622ae1f-297a-47fc-856c-dbb74b7ae27f",
   "metadata": {},
   "source": [
    "### A Multi-Task Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d811eb-8a8a-496b-9316-f9fa96ef9c69",
   "metadata": {},
   "source": [
    "There are two critical parts to multi-task recommenders:\n",
    "\n",
    "- They optimize for two or more objectives, and so have two or more losses.\n",
    "- They share variables between the tasks, allowing for transfer learning.\n",
    "\n",
    "Now, let's define our models as before, but instead of having a single task, we will have two tasks: one that predicts ratings, and one that predicts movie watches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab67df5b-3aa5-4f80-b3dd-09dd5fdf43e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32\n",
    "\n",
    "user_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "      vocabulary=unique_user_ids, mask_token=None),\n",
    "  # We add 1 to account for the unknown token.\n",
    "  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "])\n",
    "\n",
    "movie_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "      vocabulary=unique_movie_titles, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "829c4555-5276-4a4c-8945-c37e71f86648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.tasks.ranking.Ranking at 0x1fb1d7fee20>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#However, now we will have two tasks. The first is the rating task.\n",
    "# Its goal is to predict the ratings as accurately as possible.\n",
    "tfrs.tasks.Ranking(\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d74521d-d64b-427f-928d-1a875c6de03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.tasks.retrieval.Retrieval at 0x1fb0a269130>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The second is the retrieval task:\n",
    "# As before, this task's goal is to predict which movies the user will or will not watch.\n",
    "tfrs.tasks.Retrieval(\n",
    "    metrics=tfrs.metrics.FactorizedTopK(\n",
    "        candidates=movies.batch(128)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e329db76-231d-47e6-bceb-47da89d64cf9",
   "metadata": {},
   "source": [
    "**Putting it together**\n",
    "\n",
    "- We put it all together in a model class.\n",
    "\n",
    "- The new component here is that - since we have two tasks and two losses - we need to decide on how important each loss is. We can do this by giving each of the losses a weight, and treating these weights as hyperparameters. \n",
    "    - If we assign a large loss weight to the rating task, our model is going to focus on predicting ratings (but still use some information from the retrieval task); if we assign a large loss weight to the retrieval task, it will focus on retrieval instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51163738-77d4-48bd-8a68-6ae6d1cf8774",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.models.Model):\n",
    "    def __init__(self, rating_weight: float, retrieval_weight: float) -> None:\n",
    "        # We take the loss weights in the constructor: this allows us to instantiate\n",
    "        # several model objects with different loss weights.\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        # User and movie models.\n",
    "        self.movie_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "            vocabulary=unique_movie_titles, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "        ])\n",
    "        self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # A small model to take in user and movie embeddings and predict ratings.\n",
    "        # We can make this as complicated as we want as long as we output a scalar\n",
    "        # as our prediction.\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(1),\n",
    "        ])\n",
    "\n",
    "        # The tasks.\n",
    "        self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "        )\n",
    "        self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=movies.batch(128).map(self.movie_model)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # The loss weights.\n",
    "        self.rating_weight = rating_weight\n",
    "        self.retrieval_weight = retrieval_weight\n",
    "\n",
    "    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        # And pick out the movie features and pass them into the movie model.\n",
    "        movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "\n",
    "        return (\n",
    "            user_embeddings,\n",
    "            movie_embeddings,\n",
    "            # We apply the multi-layered rating model to a concatentation of\n",
    "            # user and movie embeddings.\n",
    "            self.rating_model(\n",
    "                tf.concat([user_embeddings, movie_embeddings], axis=1)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        ratings = features.pop(\"user_rating\")\n",
    "\n",
    "        user_embeddings, movie_embeddings, rating_predictions = self(features)\n",
    "\n",
    "        # We compute the loss for each task.\n",
    "        rating_loss = self.rating_task(\n",
    "                                      labels=ratings,\n",
    "                                      predictions=rating_predictions,\n",
    "                                      )\n",
    "        retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)\n",
    "\n",
    "        # And combine them using the loss weights.\n",
    "        return (self.rating_weight * rating_loss\n",
    "                + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1830dfa-7242-4940-8e6c-bc2a1ba1a498",
   "metadata": {},
   "source": [
    "#### Rating-specialized model\n",
    "\n",
    "**Depending on the weights we assign, the model will encode a different balance of the tasks. Let's start with a model that only considers ratings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f207931-3860-44aa-9606-5459e07cf907",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovielensModel(rating_weight=1.0, retrieval_weight=0.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8fd01d70-69a7-4abc-b68d-22a86a549b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then shuffling, batching, and caching the training and evaluation data:\n",
    "# Segmenting the batches so that the model runs 13 training batches (2^13) and 11 test batches (2^11) per epoch, \n",
    "# while having a batch size which is a multiple of 2^n.\n",
    "cached_train = train.shuffle(l).batch(8192).cache()\n",
    "cached_test = test.batch(2048).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "108f0db4-3a6d-45e5-8a2f-7801c79dd18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "9/9 [==============================] - 6s 537ms/step - root_mean_squared_error: 2.7931 - factorized_top_k/top_1_categorical_accuracy: 0.0883 - factorized_top_k/top_5_categorical_accuracy: 0.1250 - factorized_top_k/top_10_categorical_accuracy: 0.1446 - factorized_top_k/top_50_categorical_accuracy: 0.2018 - factorized_top_k/top_100_categorical_accuracy: 0.2409 - loss: 6.5844 - regularization_loss: 0.0000e+00 - total_loss: 6.5844\n",
      "Epoch 2/8\n",
      "9/9 [==============================] - 5s 601ms/step - root_mean_squared_error: 1.2663 - factorized_top_k/top_1_categorical_accuracy: 0.0900 - factorized_top_k/top_5_categorical_accuracy: 0.1269 - factorized_top_k/top_10_categorical_accuracy: 0.1489 - factorized_top_k/top_50_categorical_accuracy: 0.2305 - factorized_top_k/top_100_categorical_accuracy: 0.2763 - loss: 1.5562 - regularization_loss: 0.0000e+00 - total_loss: 1.5562\n",
      "Epoch 3/8\n",
      "9/9 [==============================] - 5s 554ms/step - root_mean_squared_error: 1.1430 - factorized_top_k/top_1_categorical_accuracy: 0.0759 - factorized_top_k/top_5_categorical_accuracy: 0.1105 - factorized_top_k/top_10_categorical_accuracy: 0.1280 - factorized_top_k/top_50_categorical_accuracy: 0.2114 - factorized_top_k/top_100_categorical_accuracy: 0.2665 - loss: 1.2868 - regularization_loss: 0.0000e+00 - total_loss: 1.2868\n",
      "Epoch 4/8\n",
      "9/9 [==============================] - 5s 557ms/step - root_mean_squared_error: 1.1019 - factorized_top_k/top_1_categorical_accuracy: 0.0710 - factorized_top_k/top_5_categorical_accuracy: 0.1068 - factorized_top_k/top_10_categorical_accuracy: 0.1205 - factorized_top_k/top_50_categorical_accuracy: 0.1983 - factorized_top_k/top_100_categorical_accuracy: 0.2649 - loss: 1.2086 - regularization_loss: 0.0000e+00 - total_loss: 1.2086\n",
      "Epoch 5/8\n",
      "9/9 [==============================] - 5s 593ms/step - root_mean_squared_error: 1.0995 - factorized_top_k/top_1_categorical_accuracy: 0.0736 - factorized_top_k/top_5_categorical_accuracy: 0.1043 - factorized_top_k/top_10_categorical_accuracy: 0.1196 - factorized_top_k/top_50_categorical_accuracy: 0.1927 - factorized_top_k/top_100_categorical_accuracy: 0.2604 - loss: 1.2016 - regularization_loss: 0.0000e+00 - total_loss: 1.2016\n",
      "Epoch 6/8\n",
      "9/9 [==============================] - 5s 567ms/step - root_mean_squared_error: 1.0913 - factorized_top_k/top_1_categorical_accuracy: 0.0730 - factorized_top_k/top_5_categorical_accuracy: 0.1036 - factorized_top_k/top_10_categorical_accuracy: 0.1161 - factorized_top_k/top_50_categorical_accuracy: 0.1932 - factorized_top_k/top_100_categorical_accuracy: 0.2488 - loss: 1.1835 - regularization_loss: 0.0000e+00 - total_loss: 1.1835\n",
      "Epoch 7/8\n",
      "9/9 [==============================] - 5s 580ms/step - root_mean_squared_error: 1.0824 - factorized_top_k/top_1_categorical_accuracy: 0.0729 - factorized_top_k/top_5_categorical_accuracy: 0.1029 - factorized_top_k/top_10_categorical_accuracy: 0.1123 - factorized_top_k/top_50_categorical_accuracy: 0.1900 - factorized_top_k/top_100_categorical_accuracy: 0.2403 - loss: 1.1634 - regularization_loss: 0.0000e+00 - total_loss: 1.1634\n",
      "Epoch 8/8\n",
      "9/9 [==============================] - 6s 621ms/step - root_mean_squared_error: 1.0713 - factorized_top_k/top_1_categorical_accuracy: 0.0712 - factorized_top_k/top_5_categorical_accuracy: 0.1007 - factorized_top_k/top_10_categorical_accuracy: 0.1116 - factorized_top_k/top_50_categorical_accuracy: 0.1843 - factorized_top_k/top_100_categorical_accuracy: 0.2339 - loss: 1.1387 - regularization_loss: 0.0000e+00 - total_loss: 1.1387\n"
     ]
    }
   ],
   "source": [
    "history_train  = model.fit(cached_train, epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d62c9db-6fa0-417e-b7b3-2fab28b4f3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 1152x432 with 1 Axes>, <AxesSubplot:>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fb0a3ac280>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Total Loss over epochs')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss Total')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize = (16,6))\n",
    "plt.plot(history_train.history['total_loss'] )\n",
    "plt.title(\"Total Loss over epochs\", fontsize=14)\n",
    "plt.ylabel('Loss Total')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaf8311-4a5f-4701-9c5b-ac08b6519dab",
   "metadata": {},
   "source": [
    "As the model trains, the loss is falling and a set of top-k retrieval metrics is updated. \n",
    "- These tell us whether the true positive is in the top-k retrieved items from the entire candidate set. \n",
    "- For example, a top-5 categorical accuracy metric of 0.2 would tell us that, on average, the true positive is in the top 5 retrieved items 20% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "291a4c37-6e54-426b-ae78-79118b6dfe9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 2s 110ms/step - root_mean_squared_error: 1.0711 - factorized_top_k/top_1_categorical_accuracy: 0.0723 - factorized_top_k/top_5_categorical_accuracy: 0.1022 - factorized_top_k/top_10_categorical_accuracy: 0.1153 - factorized_top_k/top_50_categorical_accuracy: 0.1852 - factorized_top_k/top_100_categorical_accuracy: 0.2359 - loss: 1.1437 - regularization_loss: 0.0000e+00 - total_loss: 1.1437\n",
      "Retrieval top-100 accuracy: 0.236.\n",
      "Ranking RMSE: 1.071.\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0da8d4d-2140-48f5-85b9-c9c0fd120017",
   "metadata": {},
   "source": [
    "**We get a good RMSE but with poor prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6972ab96-ece6-4d4b-a3cc-3b822bdc46ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Retrieval-specialized model\n",
    "**Let's now try a model that focuses on retrieval only.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14261ec7-2b09-42cf-9b84-4c77aeb84c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovielensModel(rating_weight=0.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f82a5d9e-96b4-4a5d-9686-020dc98694bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "9/9 [==============================] - 6s 548ms/step - root_mean_squared_error: 3.7024 - factorized_top_k/top_1_categorical_accuracy: 2.8577e-04 - factorized_top_k/top_5_categorical_accuracy: 5.2643e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0010 - factorized_top_k/top_50_categorical_accuracy: 0.0225 - factorized_top_k/top_100_categorical_accuracy: 0.0576 - loss: 60356.6773 - regularization_loss: 0.0000e+00 - total_loss: 60356.6773\n",
      "Epoch 2/8\n",
      "9/9 [==============================] - 5s 547ms/step - root_mean_squared_error: 3.7024 - factorized_top_k/top_1_categorical_accuracy: 2.8577e-04 - factorized_top_k/top_5_categorical_accuracy: 5.2643e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0010 - factorized_top_k/top_50_categorical_accuracy: 0.0225 - factorized_top_k/top_100_categorical_accuracy: 0.0576 - loss: 60356.6773 - regularization_loss: 0.0000e+00 - total_loss: 60356.6773\n",
      "Epoch 3/8\n",
      "9/9 [==============================] - 5s 553ms/step - root_mean_squared_error: 3.7024 - factorized_top_k/top_1_categorical_accuracy: 2.8577e-04 - factorized_top_k/top_5_categorical_accuracy: 5.2643e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0010 - factorized_top_k/top_50_categorical_accuracy: 0.0225 - factorized_top_k/top_100_categorical_accuracy: 0.0576 - loss: 60356.6773 - regularization_loss: 0.0000e+00 - total_loss: 60356.6773\n",
      "Epoch 4/8\n",
      "9/9 [==============================] - 5s 561ms/step - root_mean_squared_error: 3.7024 - factorized_top_k/top_1_categorical_accuracy: 2.8577e-04 - factorized_top_k/top_5_categorical_accuracy: 5.2643e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0010 - factorized_top_k/top_50_categorical_accuracy: 0.0225 - factorized_top_k/top_100_categorical_accuracy: 0.0576 - loss: 60356.6773 - regularization_loss: 0.0000e+00 - total_loss: 60356.6773\n",
      "Epoch 5/8\n",
      "9/9 [==============================] - 5s 567ms/step - root_mean_squared_error: 3.7024 - factorized_top_k/top_1_categorical_accuracy: 2.8577e-04 - factorized_top_k/top_5_categorical_accuracy: 5.2643e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0010 - factorized_top_k/top_50_categorical_accuracy: 0.0225 - factorized_top_k/top_100_categorical_accuracy: 0.0576 - loss: 60356.6773 - regularization_loss: 0.0000e+00 - total_loss: 60356.6773\n",
      "Epoch 6/8\n",
      "9/9 [==============================] - 5s 591ms/step - root_mean_squared_error: 3.7024 - factorized_top_k/top_1_categorical_accuracy: 2.8577e-04 - factorized_top_k/top_5_categorical_accuracy: 5.2643e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0010 - factorized_top_k/top_50_categorical_accuracy: 0.0225 - factorized_top_k/top_100_categorical_accuracy: 0.0576 - loss: 60356.6773 - regularization_loss: 0.0000e+00 - total_loss: 60356.6773\n",
      "Epoch 7/8\n",
      "9/9 [==============================] - 5s 563ms/step - root_mean_squared_error: 3.7024 - factorized_top_k/top_1_categorical_accuracy: 2.8577e-04 - factorized_top_k/top_5_categorical_accuracy: 5.2643e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0010 - factorized_top_k/top_50_categorical_accuracy: 0.0225 - factorized_top_k/top_100_categorical_accuracy: 0.0576 - loss: 60356.6773 - regularization_loss: 0.0000e+00 - total_loss: 60356.6773\n",
      "Epoch 8/8\n",
      "9/9 [==============================] - 5s 569ms/step - root_mean_squared_error: 3.7024 - factorized_top_k/top_1_categorical_accuracy: 2.8577e-04 - factorized_top_k/top_5_categorical_accuracy: 5.2643e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0010 - factorized_top_k/top_50_categorical_accuracy: 0.0225 - factorized_top_k/top_100_categorical_accuracy: 0.0576 - loss: 60356.6773 - regularization_loss: 0.0000e+00 - total_loss: 60356.6773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fb0a521f10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 2s 134ms/step - root_mean_squared_error: 3.6912 - factorized_top_k/top_1_categorical_accuracy: 3.1586e-04 - factorized_top_k/top_5_categorical_accuracy: 6.7683e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0013 - factorized_top_k/top_50_categorical_accuracy: 0.0229 - factorized_top_k/top_100_categorical_accuracy: 0.0578 - loss: 15094.9468 - regularization_loss: 0.0000e+00 - total_loss: 15094.9468\n",
      "Retrieval top-100 accuracy: 0.058.\n",
      "Ranking RMSE: 3.691.\n"
     ]
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=8)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfafedbf-cae2-4af3-8ecc-042291dbb01c",
   "metadata": {},
   "source": [
    "**We get a less impressive RMSE coupled with a poor prediction too**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4963b2b4-0e79-4e38-b036-9bef767a37aa",
   "metadata": {},
   "source": [
    "### Joint model: Baseline\n",
    "\n",
    "**Let's now train a model that assigns positive weights to both tasks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ffc394e3-2e64-4010-87a6-b404ae5d945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovielensModel(rating_weight=1.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4965a319-8005-4810-9a77-17f7c241b2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "9/9 [==============================] - 6s 560ms/step - root_mean_squared_error: 2.7752 - factorized_top_k/top_1_categorical_accuracy: 0.0899 - factorized_top_k/top_5_categorical_accuracy: 0.1295 - factorized_top_k/top_10_categorical_accuracy: 0.1496 - factorized_top_k/top_50_categorical_accuracy: 0.2214 - factorized_top_k/top_100_categorical_accuracy: 0.2597 - loss: 60363.1939 - regularization_loss: 0.0000e+00 - total_loss: 60363.1939\n",
      "Epoch 2/8\n",
      "9/9 [==============================] - 5s 606ms/step - root_mean_squared_error: 1.2133 - factorized_top_k/top_1_categorical_accuracy: 0.0827 - factorized_top_k/top_5_categorical_accuracy: 0.1292 - factorized_top_k/top_10_categorical_accuracy: 0.1498 - factorized_top_k/top_50_categorical_accuracy: 0.2343 - factorized_top_k/top_100_categorical_accuracy: 0.2830 - loss: 60358.1180 - regularization_loss: 0.0000e+00 - total_loss: 60358.1180\n",
      "Epoch 3/8\n",
      "9/9 [==============================] - 5s 557ms/step - root_mean_squared_error: 1.1141 - factorized_top_k/top_1_categorical_accuracy: 0.0785 - factorized_top_k/top_5_categorical_accuracy: 0.1240 - factorized_top_k/top_10_categorical_accuracy: 0.1409 - factorized_top_k/top_50_categorical_accuracy: 0.2269 - factorized_top_k/top_100_categorical_accuracy: 0.2769 - loss: 60357.9208 - regularization_loss: 0.0000e+00 - total_loss: 60357.9208\n",
      "Epoch 4/8\n",
      "9/9 [==============================] - 5s 564ms/step - root_mean_squared_error: 1.1062 - factorized_top_k/top_1_categorical_accuracy: 0.0784 - factorized_top_k/top_5_categorical_accuracy: 0.1235 - factorized_top_k/top_10_categorical_accuracy: 0.1450 - factorized_top_k/top_50_categorical_accuracy: 0.2276 - factorized_top_k/top_100_categorical_accuracy: 0.2806 - loss: 60357.9053 - regularization_loss: 0.0000e+00 - total_loss: 60357.9053\n",
      "Epoch 5/8\n",
      "9/9 [==============================] - 5s 591ms/step - root_mean_squared_error: 1.1033 - factorized_top_k/top_1_categorical_accuracy: 0.0848 - factorized_top_k/top_5_categorical_accuracy: 0.1235 - factorized_top_k/top_10_categorical_accuracy: 0.1423 - factorized_top_k/top_50_categorical_accuracy: 0.2314 - factorized_top_k/top_100_categorical_accuracy: 0.2755 - loss: 60357.8980 - regularization_loss: 0.0000e+00 - total_loss: 60357.8980\n",
      "Epoch 6/8\n",
      "9/9 [==============================] - 5s 582ms/step - root_mean_squared_error: 1.0997 - factorized_top_k/top_1_categorical_accuracy: 0.0855 - factorized_top_k/top_5_categorical_accuracy: 0.1221 - factorized_top_k/top_10_categorical_accuracy: 0.1425 - factorized_top_k/top_50_categorical_accuracy: 0.2291 - factorized_top_k/top_100_categorical_accuracy: 0.2790 - loss: 60357.8893 - regularization_loss: 0.0000e+00 - total_loss: 60357.8893\n",
      "Epoch 7/8\n",
      "9/9 [==============================] - 5s 585ms/step - root_mean_squared_error: 1.0943 - factorized_top_k/top_1_categorical_accuracy: 0.0832 - factorized_top_k/top_5_categorical_accuracy: 0.1240 - factorized_top_k/top_10_categorical_accuracy: 0.1429 - factorized_top_k/top_50_categorical_accuracy: 0.2269 - factorized_top_k/top_100_categorical_accuracy: 0.2829 - loss: 60357.8762 - regularization_loss: 0.0000e+00 - total_loss: 60357.8762\n",
      "Epoch 8/8\n",
      "9/9 [==============================] - 5s 594ms/step - root_mean_squared_error: 1.0867 - factorized_top_k/top_1_categorical_accuracy: 0.0832 - factorized_top_k/top_5_categorical_accuracy: 0.1260 - factorized_top_k/top_10_categorical_accuracy: 0.1448 - factorized_top_k/top_50_categorical_accuracy: 0.2246 - factorized_top_k/top_100_categorical_accuracy: 0.2771 - loss: 60357.8569 - regularization_loss: 0.0000e+00 - total_loss: 60357.8569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fb0a521e80>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 2s 131ms/step - root_mean_squared_error: 1.0865 - factorized_top_k/top_1_categorical_accuracy: 0.0888 - factorized_top_k/top_5_categorical_accuracy: 0.1375 - factorized_top_k/top_10_categorical_accuracy: 0.1474 - factorized_top_k/top_50_categorical_accuracy: 0.2260 - factorized_top_k/top_100_categorical_accuracy: 0.2854 - loss: 15096.1242 - regularization_loss: 0.0000e+00 - total_loss: 15096.1242\n",
      "Retrieval top-100 accuracy: 0.285.\n",
      "Ranking RMSE: 1.087.\n"
     ]
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=8)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756688df-1e35-47ac-9e12-0e04a15e71a5",
   "metadata": {},
   "source": [
    "### Summary of the Baseline Joint Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d9c769-7dc7-42d2-b69b-e5204ea984d3",
   "metadata": {},
   "source": [
    "| Models | Retrieval top-10 accuracy | Retrieval top-100 accuracy | Ranking RMSE |\n",
    "| --- | --- | --- | --- |\n",
    "| Model: Rating-specialized model | 0.1153 | 0.236 | 1.071 |\n",
    "| Model: Retrieval-specialized model | 0.0013 | 0.058 | 3.691 |\n",
    "| Model: Joint model: Baseline | 0.1474 | 0.285 | 1.087 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e32b83-de6b-426b-aa24-6a6e3d3eb095",
   "metadata": {},
   "source": [
    "**The joint model seems to provide an overall better prediction than the other independent models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be27bd1-be4a-4184-bf28-eaee97f0a77c",
   "metadata": {},
   "source": [
    "**What can we improve upon the joint model?**\n",
    "\n",
    "- Adding more features\n",
    "- Optimize Embedding\n",
    "- embedding_dimension\n",
    "- epochs= 8 to 16\n",
    "- Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7828a63-afd9-4d82-8df3-dbed9f0d3e15",
   "metadata": {},
   "source": [
    "#### Case 2: Tuned Joint Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca3e0144-19ff-4a98-a04c-39c1d63e3dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-Loading the datasets\n",
    "# Ratings data.\n",
    "ratings = pd.read_csv('ratings.csv', encoding='ISO-8859-1')\n",
    "# Features of all the available movies.\n",
    "movies = pd.read_csv('df_movies.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fde81b41-c316-4d4c-abd6-ebbff28b7c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure the types are consistend with tf\n",
    "ratings['movie_id'] = ratings['movie_id'].astype('str')\n",
    "movies['movie_id'] = movies['movie_id'].astype('str')\n",
    "ratings['user_id'] = ratings['user_id'].astype('str')\n",
    "ratings['user_zip_code'] = ratings['user_zip_code'].astype('str')\n",
    "ratings['bucketized_user_age'] = ratings['bucketized_user_age'].astype('int64')\n",
    "ratings['timestamp'] = ratings['timestamp'].astype('int64')\n",
    "ratings['release_date'] = ratings['release_date'].astype('int64')\n",
    "ratings['user_rating'] = ratings['user_rating'].astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53f739d0-b072-49ac-acf0-80303c8bc85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>data_type</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bucketized_user_age</th>\n",
       "      <td>7</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_genres</th>\n",
       "      <td>179</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <td>1117</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_title</th>\n",
       "      <td>1099</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <td>40530</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_gender</th>\n",
       "      <td>2</td>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>925</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_occupation_label</th>\n",
       "      <td>17</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_occupation_text</th>\n",
       "      <td>21</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_rating</th>\n",
       "      <td>5</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_zip_code</th>\n",
       "      <td>778</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director</th>\n",
       "      <td>976</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>release_date</th>\n",
       "      <td>995</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star</th>\n",
       "      <td>915</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count data_type missing_count missing%\n",
       "bucketized_user_age        7     int64             0      0.0\n",
       "movie_genres             179    object             0      0.0\n",
       "movie_id                1117    object             0      0.0\n",
       "movie_title             1099    object             0      0.0\n",
       "timestamp              40530     int64             0      0.0\n",
       "user_gender                2      bool             0      0.0\n",
       "user_id                  925    object             0      0.0\n",
       "user_occupation_label     17     int64             0      0.0\n",
       "user_occupation_text      21    object             0      0.0\n",
       "user_rating                5     int64             0      0.0\n",
       "user_zip_code            778    object             0      0.0\n",
       "director                 976    object             0      0.0\n",
       "release_date             995     int64             0      0.0\n",
       "star                     915    object             0      0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's have a general view:\n",
    "ratings_missing = pd.concat([ratings.nunique(), ratings.dtypes, ratings.isnull().sum(), 100*ratings.isnull().mean()], axis=1)\n",
    "ratings_missing.columns = [['count', 'data_type', 'missing_count', 'missing%']]\n",
    "ratings_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "612a89b1-06da-4aa1-a7e3-ca9ae8f1986d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>data_type</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>1682</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_genres</th>\n",
       "      <td>216</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <td>1682</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_title</th>\n",
       "      <td>1664</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count data_type missing_count missing%\n",
       "Unnamed: 0    1682     int64             0      0.0\n",
       "movie_genres   216    object             0      0.0\n",
       "movie_id      1682    object             0      0.0\n",
       "movie_title   1664    object             0      0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's have a general view:\n",
    "movies_missing = pd.concat([movies.nunique(), movies.dtypes, movies.isnull().sum(), 100*movies.isnull().mean()], axis=1)\n",
    "movies_missing.columns = [['count', 'data_type', 'missing_count', 'missing%']]\n",
    "movies_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06ebf39-7c79-4e6b-afbb-8e73b3070848",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implementing a Retrieval Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "24e280b1-c98d-48a7-9948-513b11d71813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's wrap the **pandas dataframe** into **tf.data.Dataset** object using **tf.data.Dataset.from_tensor_slices** using: tf.data.Dataset.from_tensor_slices\n",
    "ratings = tf.data.Dataset.from_tensor_slices(dict(ratings))\n",
    "movies = tf.data.Dataset.from_tensor_slices(dict(movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f24b3e0-a2b8-4a5b-936c-5715fce1cce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': 45,\n",
      " 'director': b'Milos Forman',\n",
      " 'movie_genres': b'[7]',\n",
      " 'movie_id': b'357',\n",
      " 'movie_title': b\"One Flew Over the Cuckoo's Nest\",\n",
      " 'release_date': 185500800,\n",
      " 'star': b'Jack Nicholson',\n",
      " 'timestamp': 879024327,\n",
      " 'user_gender': True,\n",
      " 'user_id': b'138',\n",
      " 'user_occupation_label': 4,\n",
      " 'user_occupation_text': b'doctor',\n",
      " 'user_rating': 4,\n",
      " 'user_zip_code': b'53211'}\n"
     ]
    }
   ],
   "source": [
    "#The ratings dataset returns a dictionary of movie id, user id, the assigned rating, timestamp, movie information, and user information:\n",
    "#View the data from the ratings dataset:\n",
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7811e73d-27be-4359-a93f-51d5d6e73b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Unnamed: 0': 0,\n",
      " 'movie_genres': b'[4]',\n",
      " 'movie_id': b\"b'1681'\",\n",
      " 'movie_title': b\"b'You So Crazy (1994)'\"}\n"
     ]
    }
   ],
   "source": [
    "#The ratings dataset returns a dictionary of movie id, user id, the assigned rating, timestamp, movie information, and user information:\n",
    "#View the data from the movies dataset:\n",
    "for x in movies.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d7b8af1-39dd-4b4a-957a-805b418efc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the basic features.\n",
    "ratings = ratings.map(lambda x: {\n",
    "                                \"movie_title\": x[\"movie_title\"],\n",
    "                                \"user_id\": x[\"user_id\"],\n",
    "                                \"user_rating\": x[\"user_rating\"],\n",
    "                                \"timestamp\": x[\"timestamp\"],\n",
    "                                \"bucketized_user_age\": x['bucketized_user_age'],\n",
    "                                \"gender\": tf.dtypes.cast(x[\"user_gender\"], tf.int64),\n",
    "                                \"director\": x[\"director\"],\n",
    "                                \"star\": x[\"star\"],\n",
    "                               })\n",
    "movies = movies.map(lambda x: {\n",
    "                                \"movie_title\": x[\"movie_title\"], \n",
    "                                \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f44ab3c1-d795-44ce-9ba5-76b8ec966f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use a random split, putting 75% of the ratings in the train set, and 25% in the test set:\n",
    "# Assign a seed=42 for consistency of results and reproducibility:\n",
    "seed = 42\n",
    "l = len(ratings)\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "shuffled = ratings.shuffle(l, seed=seed, reshuffle_each_iteration=False)\n",
    "\n",
    "#Save 80% of the data for training and 20% for testing:\n",
    "train_ = int(0.75 * l)\n",
    "test_ = int(0.25 * l)\n",
    "\n",
    "train = shuffled.take(train_)\n",
    "test = shuffled.skip(train_).take(test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9fb849ea-857e-4ddf-990d-dd4d3a7e944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffling data and splitting between train and test.\n",
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(1_000_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(800_000)\n",
    "test = shuffled.skip(800_000).take(200_000)\n",
    "\n",
    "movie_titles = movies.batch(10_000).map(lambda x: x[\"movie_title\"])\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f3c87035-51b4-474c-ad10-1e8639cb6915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'b\"\\'Til There Was You (1997)\"',\n",
       "       b'b\"Amityville 1992: It\\'s About Time (1992)\"',\n",
       "       b'b\"Antonia\\'s Line (1995)\"', b'b\"April Fool\\'s Day (1986)\"',\n",
       "       b'b\"Blood For Dracula (Andy Warhol\\'s Dracula) (1974)\"',\n",
       "       b'b\"Boy\\'s Life 2 (1997)\"', b'b\"Bram Stoker\\'s Dracula (1992)\"',\n",
       "       b'b\"Breakfast at Tiffany\\'s (1961)\"',\n",
       "       b'b\"Brother\\'s Kiss, A (1997)\"',\n",
       "       b'b\"C\\'est arriv\\\\xc3\\\\xa9 pr\\\\xc3\\\\xa8s de chez vous (1992)\"'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "unique_movie_titles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "44196c6e-1eee-438d-8de6-16f089204031",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = np.concatenate(list(ratings.map(lambda x: x[\"timestamp\"]).batch(100)))\n",
    "\n",
    "max_timestamp = timestamps.max()\n",
    "min_timestamp = timestamps.min()\n",
    "\n",
    "timestamp_buckets = np.linspace(\n",
    "    min_timestamp, max_timestamp, num=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c1761ecf-ab03-4dcc-ba00-d63d137c95d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_age = ratings.batch(1_000_000).map(lambda x: x[\"bucketized_user_age\"])\n",
    "unique_user_age = np.unique(np.concatenate(list(user_age)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b646ae65-b401-45c5-81a6-e195b66c9b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_age = unique_user_age.max()\n",
    "min_age = unique_user_age.min()\n",
    "\n",
    "age_buckets = np.linspace(\n",
    "                         min_age, \n",
    "                         max_age, \n",
    "                         num=7,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a643a42-74e6-4e47-92af-b066520276c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 10, 19, 28, 37, 46, 56], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_buckets = age_buckets.astype('int64')\n",
    "age_buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e594f777-6cde-4328-9da2-b6216e0e9c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_gender = ratings.batch(1_000_000).map(lambda x: x['gender'] )\n",
    "unique_user_gender = np.unique(np.concatenate(list(user_gender)))\n",
    "unique_user_gender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22ab28c-1cab-4076-bc78-eeb14579f990",
   "metadata": {},
   "source": [
    "####  A Multi-Task Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be08fdd7-cb53-4d19-8634-1cef11e23fa0",
   "metadata": {},
   "source": [
    "There are two critical parts to multi-task recommenders:\n",
    "\n",
    "- They optimize for two or more objectives, and so have two or more losses.\n",
    "- They share variables between the tasks, allowing for transfer learning.\n",
    "\n",
    "Now, let's define our models as before, but instead of having a single task, we will have two tasks: one that predicts ratings, and one that predicts movie watches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "75c78543-4724-4888-92e5-3b34701f9dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32\n",
    "\n",
    "user_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "      vocabulary=unique_user_ids, mask_token=None),\n",
    "  # We add 1 to account for the unknown token.\n",
    "  tf.keras.layers.Embedding(len(unique_user_ids) + 2, embedding_dimension)\n",
    "])\n",
    "\n",
    "movie_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "      vocabulary=unique_movie_titles, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_movie_titles) + 2, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbc2e77-547d-4634-92bc-1ead06660b1a",
   "metadata": {},
   "source": [
    "**However, now we will have two tasks. The first is the rating task:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b7b5d4c6-8e74-4204-968f-f889a03a932d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.tasks.ranking.Ranking at 0x1fb0a6ab2e0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfrs.tasks.Ranking(\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c1f2d4-1f6f-4798-9efe-a8f8952fe4be",
   "metadata": {},
   "source": [
    "**Its goal is to predict the ratings as accurately as possible.**\n",
    "\n",
    "**The second is the retrieval task:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "337a889e-8e49-419e-97f7-009869407c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.tasks.retrieval.Retrieval at 0x1fb7f13df70>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfrs.tasks.Retrieval(\n",
    "    metrics=tfrs.metrics.FactorizedTopK(\n",
    "        candidates=movies.batch(128)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26efc33a-bcfa-45e4-8bf4-e20061a1d9ae",
   "metadata": {},
   "source": [
    "As before, this task's goal is to predict which movies the user will or will not watch.\n",
    "\n",
    "Those folowwing classes were re-configured to accomodate the new embedded design due to new features, having deeper neural networks and adding regularization to help overfitting:\n",
    "\n",
    "- class UserModel\n",
    "- class QueryModel\n",
    "- class MovieModel\n",
    "- class MovieModel\n",
    "- class CandidateModel\n",
    "- class MovielensModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "64626113-fb07-4b29-98ca-560a22a0de5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension),\n",
    "\n",
    "        ])\n",
    "        self.timestamp_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.Discretization(timestamp_buckets.tolist()),\n",
    "            tf.keras.layers.Embedding(len(timestamp_buckets) + 1, embedding_dimension),\n",
    "\n",
    "        ])\n",
    "        self.normalized_timestamp = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "\n",
    "        self.normalized_timestamp.adapt(timestamps)\n",
    "\n",
    "      #  self.age_embedding = tf.keras.Sequential([\n",
    "       #     tf.keras.layers.experimental.preprocessing.Discretization(age_buckets.tolist()),\n",
    "        #    tf.keras.layers.Embedding(len(age_buckets) + 1, embedding_dimension//2),\n",
    "      #  ])\n",
    "\n",
    "        #self.normalized_age = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "\n",
    "       # self.normalized_age.adapt(unique_user_age)\n",
    "\n",
    "        self.gender_embedding = tf.keras.layers.experimental.preprocessing.CategoryEncoding(\n",
    "            max_tokens=len(unique_user_gender) + 1)\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Take the input dictionary, pass it through each input layer,\n",
    "        # and concatenate the result.\n",
    "        return tf.concat([\n",
    "            self.user_embedding(inputs[\"user_id\"]),\n",
    "            self.timestamp_embedding(inputs[\"timestamp\"]),\n",
    "            self.normalized_timestamp(inputs[\"timestamp\"]),\n",
    "            #self.age_embedding(inputs[\"user_age\"]),\n",
    "            #self.normalized_age(inputs[\"user_age\"]),\n",
    "            self.gender_embedding(inputs[\"gender\"])\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "59b4e7b8-4918-4273-8217-e0ab35a2cb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryModel(tf.keras.Model):\n",
    "    \"\"\"Model for encoding user queries.\"\"\"\n",
    "\n",
    "    def __init__(self, layer_sizes):\n",
    "        \"\"\"Model for encoding user queries.\n",
    "\n",
    "        Args:\n",
    "          layer_sizes:\n",
    "            A list of integers where the i-th entry represents the number of units\n",
    "            the i-th layer contains.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # We first use the user model for generating embeddings.\n",
    "        self.embedding_model = UserModel()\n",
    "\n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = tf.keras.Sequential()\n",
    "\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "        # No activation for the last layer.\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
    "            self.dense_layers.add(tf.keras.layers.Dropout(0.2))\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        feature_embedding = self.embedding_model(inputs)\n",
    "        return self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "330fcaa2-46b9-4c72-8818-4d21ae06577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        max_tokens = 10_000\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        self.title_embedding = tf.keras.Sequential([\n",
    "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "              vocabulary=unique_movie_titles,mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension),\n",
    "\n",
    "        ])\n",
    "\n",
    "        self.title_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "            max_tokens=max_tokens)\n",
    "\n",
    "        self.title_text_embedding = tf.keras.Sequential([\n",
    "          self.title_vectorizer,\n",
    "          tf.keras.layers.Embedding(max_tokens, embedding_dimension, mask_zero=True),\n",
    "          tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        ])\n",
    "\n",
    "        self.title_vectorizer.adapt(movies.map(lambda x: x['movie_title']))\n",
    "\n",
    "    def call(self, titles):\n",
    "        return tf.concat([\n",
    "            self.title_embedding(titles),\n",
    "            self.title_text_embedding(titles),\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3d25a5a9-3275-4499-83aa-b2d3a0220782",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CandidateModel(tf.keras.Model):\n",
    "    \"\"\"Model for encoding movies.\"\"\"\n",
    "\n",
    "    def __init__(self, layer_sizes):\n",
    "        \"\"\"Model for encoding movies.\n",
    "\n",
    "        Args:\n",
    "          layer_sizes:\n",
    "            A list of integers where the i-th entry represents the number of units\n",
    "            the i-th layer contains.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_model = MovieModel()\n",
    "\n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = tf.keras.Sequential()\n",
    "\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "            self.dense_layers.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "        # No activation for the last layer.\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
    "    \n",
    "    def call(self, inputs):\n",
    "            feature_embedding = self.embedding_model(inputs)\n",
    "            return self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "66edb7c6-fcdc-430b-a010-bc01ac1f7275",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.models.Model):\n",
    "    def __init__(self, rating_weight: float, retrieval_weight: float) -> None:\n",
    "        # We take the loss weights in the constructor: this allows us to instantiate\n",
    "        # several model objects with different loss weights.\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        layer_sizes = [64, 32, 32, 32, 32]\n",
    "\n",
    "        # User and movie models.\n",
    "        self.movie_model: tf.keras.layers.Layer = CandidateModel(layer_sizes)\n",
    "\n",
    "        self.user_model: tf.keras.layers.Layer = QueryModel(layer_sizes)\n",
    "\n",
    "        # A small model to take in user and movie embeddings and predict ratings.\n",
    "        # We can make this as complicated as we want as long as we output a scalar\n",
    "        # as our prediction.\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(1),\n",
    "        ])\n",
    "\n",
    "        # The tasks.\n",
    "        self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "        )\n",
    "        self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=movies.batch(128).map(lambda x: x['movie_title']).map(self.movie_model)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # The loss weights.\n",
    "        self.rating_weight = rating_weight\n",
    "        self.retrieval_weight = retrieval_weight\n",
    "\n",
    "    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        user_embeddings = self.user_model({\n",
    "            \"user_id\": features[\"user_id\"],\n",
    "            \"timestamp\": features[\"timestamp\"],\n",
    "           # \"user_age\": features[\"user_age\"],\n",
    "            \"gender\": features[\"gender\"],\n",
    "        })\n",
    "        # And pick out the movie features and pass them into the movie model.\n",
    "        movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "\n",
    "        return (\n",
    "            user_embeddings,\n",
    "            movie_embeddings,\n",
    "            # We apply the multi-layered rating model to a concatentation of\n",
    "            # user and movie embeddings.\n",
    "            self.rating_model(\n",
    "                tf.concat([user_embeddings, movie_embeddings], axis=1)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "        user_embeddings, movie_embeddings, rating_predictions = self(features)\n",
    "\n",
    "\n",
    "        # We compute the loss for each task.\n",
    "        rating_loss = self.rating_task(\n",
    "            labels=features[\"user_rating\"],\n",
    "            predictions=rating_predictions,\n",
    "        )\n",
    "        retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)\n",
    "\n",
    "        # And combine them using the loss weights.\n",
    "        return (self.rating_weight * rating_loss\n",
    "                + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d2400e-edcf-4a5d-83d3-4f2ec7ffe8fd",
   "metadata": {},
   "source": [
    "### Joint model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c6676f-2b4d-48e5-b0ca-67aa772425be",
   "metadata": {},
   "source": [
    "Let's now train a model that assigns positive weights to both tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b2f19f0b-6ee6-45f2-b38b-ef2279a36fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x1fb0a6ad220>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "61dd7dd1-0537-4736-ac01-92d235bb2f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:max_tokens is deprecated, please use num_tokens instead.\n"
     ]
    }
   ],
   "source": [
    "model = MovielensModel(rating_weight=1.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6ba53da8-1cfa-4373-ae1b-b9a14af208bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(1_000_000).batch(8192).cache()\n",
    "cached_test = test.batch(2048).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9350d74f-3078-4d16-84f8-3dd4dd025ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize\n",
      "WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize\n",
      "WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize\n",
      "11/11 [==============================] - 11s 776ms/step - root_mean_squared_error: 3.1389 - factorized_top_k/top_1_categorical_accuracy: 0.3231 - factorized_top_k/top_5_categorical_accuracy: 0.3439 - factorized_top_k/top_10_categorical_accuracy: 0.3530 - factorized_top_k/top_50_categorical_accuracy: 0.3783 - factorized_top_k/top_100_categorical_accuracy: 0.3943 - loss: 71582.0553 - regularization_loss: 0.0000e+00 - total_loss: 71582.0553\n",
      "Epoch 2/16\n",
      "11/11 [==============================] - 9s 768ms/step - root_mean_squared_error: 2.7269 - factorized_top_k/top_1_categorical_accuracy: 0.7092 - factorized_top_k/top_5_categorical_accuracy: 0.7110 - factorized_top_k/top_10_categorical_accuracy: 0.7113 - factorized_top_k/top_50_categorical_accuracy: 0.7124 - factorized_top_k/top_100_categorical_accuracy: 0.7137 - loss: 71407.3639 - regularization_loss: 0.0000e+00 - total_loss: 71407.3639\n",
      "Epoch 3/16\n",
      "11/11 [==============================] - 8s 757ms/step - root_mean_squared_error: 1.8248 - factorized_top_k/top_1_categorical_accuracy: 6.5427e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0012 - factorized_top_k/top_10_categorical_accuracy: 0.0015 - factorized_top_k/top_50_categorical_accuracy: 0.0025 - factorized_top_k/top_100_categorical_accuracy: 0.0033 - loss: 71402.3301 - regularization_loss: 0.0000e+00 - total_loss: 71402.3301      \n",
      "Epoch 4/16\n",
      "11/11 [==============================] - 9s 807ms/step - root_mean_squared_error: 1.1122 - factorized_top_k/top_1_categorical_accuracy: 0.1728 - factorized_top_k/top_5_categorical_accuracy: 0.2033 - factorized_top_k/top_10_categorical_accuracy: 0.2155 - factorized_top_k/top_50_categorical_accuracy: 0.2501 - factorized_top_k/top_100_categorical_accuracy: 0.2710 - loss: 71403.2298 - regularization_loss: 0.0000e+00 - total_loss: 71403.2298\n",
      "Epoch 5/16\n",
      "11/11 [==============================] - 10s 871ms/step - root_mean_squared_error: 1.1223 - factorized_top_k/top_1_categorical_accuracy: 0.5727 - factorized_top_k/top_5_categorical_accuracy: 0.5799 - factorized_top_k/top_10_categorical_accuracy: 0.5837 - factorized_top_k/top_50_categorical_accuracy: 0.5862 - factorized_top_k/top_100_categorical_accuracy: 0.5871 - loss: 71427.5566 - regularization_loss: 0.0000e+00 - total_loss: 71427.5566\n",
      "Epoch 6/16\n",
      "11/11 [==============================] - 9s 810ms/step - root_mean_squared_error: 1.1110 - factorized_top_k/top_1_categorical_accuracy: 0.0121 - factorized_top_k/top_5_categorical_accuracy: 0.0129 - factorized_top_k/top_10_categorical_accuracy: 0.0132 - factorized_top_k/top_50_categorical_accuracy: 0.0140 - factorized_top_k/top_100_categorical_accuracy: 0.0146 - loss: 71389.8021 - regularization_loss: 0.0000e+00 - total_loss: 71389.8021\n",
      "Epoch 7/16\n",
      "11/11 [==============================] - 9s 844ms/step - root_mean_squared_error: 1.1134 - factorized_top_k/top_1_categorical_accuracy: 0.7716 - factorized_top_k/top_5_categorical_accuracy: 0.7968 - factorized_top_k/top_10_categorical_accuracy: 0.8017 - factorized_top_k/top_50_categorical_accuracy: 0.8104 - factorized_top_k/top_100_categorical_accuracy: 0.8156 - loss: 71343.1048 - regularization_loss: 0.0000e+00 - total_loss: 71343.1048\n",
      "Epoch 8/16\n",
      "11/11 [==============================] - 9s 783ms/step - root_mean_squared_error: 1.1314 - factorized_top_k/top_1_categorical_accuracy: 0.2266 - factorized_top_k/top_5_categorical_accuracy: 0.2278 - factorized_top_k/top_10_categorical_accuracy: 0.2281 - factorized_top_k/top_50_categorical_accuracy: 0.2287 - factorized_top_k/top_100_categorical_accuracy: 0.2292 - loss: 71395.1842 - regularization_loss: 0.0000e+00 - total_loss: 71395.1842\n",
      "Epoch 9/16\n",
      "11/11 [==============================] - 9s 827ms/step - root_mean_squared_error: 1.1108 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 71391.9336 - regularization_loss: 0.0000e+00 - total_loss: 71391.9336\n",
      "Epoch 10/16\n",
      "11/11 [==============================] - 9s 825ms/step - root_mean_squared_error: 1.1217 - factorized_top_k/top_1_categorical_accuracy: 0.2531 - factorized_top_k/top_5_categorical_accuracy: 0.2629 - factorized_top_k/top_10_categorical_accuracy: 0.2673 - factorized_top_k/top_50_categorical_accuracy: 0.2815 - factorized_top_k/top_100_categorical_accuracy: 0.2883 - loss: 71164.9557 - regularization_loss: 0.0000e+00 - total_loss: 71164.9557\n",
      "Epoch 11/16\n",
      "11/11 [==============================] - 9s 851ms/step - root_mean_squared_error: 1.1121 - factorized_top_k/top_1_categorical_accuracy: 0.6742 - factorized_top_k/top_5_categorical_accuracy: 0.6867 - factorized_top_k/top_10_categorical_accuracy: 0.6952 - factorized_top_k/top_50_categorical_accuracy: 0.7142 - factorized_top_k/top_100_categorical_accuracy: 0.7263 - loss: 70681.1647 - regularization_loss: 0.0000e+00 - total_loss: 70681.1647\n",
      "Epoch 12/16\n",
      "11/11 [==============================] - 9s 858ms/step - root_mean_squared_error: 1.1099 - factorized_top_k/top_1_categorical_accuracy: 0.8856 - factorized_top_k/top_5_categorical_accuracy: 0.8906 - factorized_top_k/top_10_categorical_accuracy: 0.8934 - factorized_top_k/top_50_categorical_accuracy: 0.9031 - factorized_top_k/top_100_categorical_accuracy: 0.9083 - loss: 70364.7591 - regularization_loss: 0.0000e+00 - total_loss: 70364.7591\n",
      "Epoch 13/16\n",
      "11/11 [==============================] - 9s 811ms/step - root_mean_squared_error: 1.1105 - factorized_top_k/top_1_categorical_accuracy: 0.9768 - factorized_top_k/top_5_categorical_accuracy: 0.9781 - factorized_top_k/top_10_categorical_accuracy: 0.9790 - factorized_top_k/top_50_categorical_accuracy: 0.9820 - factorized_top_k/top_100_categorical_accuracy: 0.9832 - loss: 70415.0273 - regularization_loss: 0.0000e+00 - total_loss: 70415.0273\n",
      "Epoch 14/16\n",
      "11/11 [==============================] - 10s 894ms/step - root_mean_squared_error: 1.1100 - factorized_top_k/top_1_categorical_accuracy: 0.9139 - factorized_top_k/top_5_categorical_accuracy: 0.9193 - factorized_top_k/top_10_categorical_accuracy: 0.9236 - factorized_top_k/top_50_categorical_accuracy: 0.9332 - factorized_top_k/top_100_categorical_accuracy: 0.9364 - loss: 70248.3496 - regularization_loss: 0.0000e+00 - total_loss: 70248.3496\n",
      "Epoch 15/16\n",
      "11/11 [==============================] - 9s 799ms/step - root_mean_squared_error: 1.1097 - factorized_top_k/top_1_categorical_accuracy: 0.9562 - factorized_top_k/top_5_categorical_accuracy: 0.9604 - factorized_top_k/top_10_categorical_accuracy: 0.9617 - factorized_top_k/top_50_categorical_accuracy: 0.9647 - factorized_top_k/top_100_categorical_accuracy: 0.9659 - loss: 70169.2474 - regularization_loss: 0.0000e+00 - total_loss: 70169.2474\n",
      "Epoch 16/16\n",
      "11/11 [==============================] - 9s 826ms/step - root_mean_squared_error: 1.1095 - factorized_top_k/top_1_categorical_accuracy: 0.9501 - factorized_top_k/top_5_categorical_accuracy: 0.9529 - factorized_top_k/top_10_categorical_accuracy: 0.9544 - factorized_top_k/top_50_categorical_accuracy: 0.9571 - factorized_top_k/top_100_categorical_accuracy: 0.9588 - loss: 70113.7591 - regularization_loss: 0.0000e+00 - total_loss: 70113.7591\n"
     ]
    }
   ],
   "source": [
    "Final = model.fit(cached_train, validation_data = cached_test, epochs=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6207ed6-cbd1-45a5-a36e-771f3aeffb11",
   "metadata": {},
   "source": [
    "### Summary of all models' metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ca3caf-7159-4a76-bc95-66ff50a1da08",
   "metadata": {},
   "source": [
    "| Models | Retrieval top-10 accuracy | Retrieval top-100 accuracy | Ranking RMSE |\n",
    "| --- | --- | --- | --- |\n",
    "| Model: Rating-specialized model | 0.1153 | 0.236 | 1.071 |\n",
    "| Model: Retrieval-specialized model | 0.0013 | 0.058 | 3.691 |\n",
    "| Model: Joint model: Baseline | 0.1474 | 0.285 | 1.087 |\n",
    "| Model: Tuned Joint model (Best Model for teh Recommendation) | 0.9544 | 0.96 | 1.11 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6eacfa8d-dbba-4616-be67-0e1822b5e083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.QueryModel at 0x1fb0a4539d0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.CandidateModel at 0x1fb0a3c2760>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0'], dtype=object)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.user_model\n",
    "model.movie_model\n",
    "tf.constant([\"0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "33dd89ff-7c1d-42bb-a487-57b2f2842d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(movie_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c640edff-398e-46c8-9801-33da66cac6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'movie_title': <tf.Tensor 'args_0:0' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'movie_title': <tf.Tensor 'args_0:0' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (<MapDataset shapes: (None, 32), types: tf.float32>) with an unsupported type (<class 'tensorflow.python.data.ops.dataset_ops.MapDataset'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MOHAME~1.ZIA\\AppData\\Local\\Temp/ipykernel_12080/1511721995.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# recommends movies out of the entire movies dataset.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmovie_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmovies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Get recommendations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_new\\lib\\site-packages\\tensorflow_recommenders\\layers\\factorized_top_k.py\u001b[0m in \u001b[0;36mindex\u001b[1;34m(self, candidates, identifiers)\u001b[0m\n\u001b[0;32m    517\u001b[0m       \u001b[0midentifiers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m       raise ValueError(\n\u001b[0;32m    521\u001b[0m           f\"The candidates tensor must be 2D (got {candidates.shape}).\")\n",
      "\u001b[1;32m~\\anaconda_new\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_new\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mrank\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    836\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mend_compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m   \"\"\"\n\u001b[1;32m--> 838\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mrank_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_new\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mrank_internal\u001b[1;34m(input, name, optimize)\u001b[0m\n\u001b[0;32m    856\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m       \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_new\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_new\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1565\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1566\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_new\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    337\u001b[0m                                          as_ref=False):\n\u001b[0;32m    338\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_new\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m--> 264\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    265\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_new\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    274\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_new\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m   \u001b[1;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_new\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Attempt to convert a value (<MapDataset shapes: (None, 32), types: tf.float32>) with an unsupported type (<class 'tensorflow.python.data.ops.dataset_ops.MapDataset'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "# Recommend the 5 best movies for user 42:\n",
    "\n",
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "\n",
    "# recommends movies out of the entire movies dataset.\n",
    "index.index(movies.batch(100).map(model.movie_model), movies)\n",
    "\n",
    "# Get recommendations.\n",
    "_, titles = index(tf.constant([\"0\"]))\n",
    "print(f\"Recommendations for user 42: {titles[0, :5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9be232-392e-45bd-9a53-b9be66b18f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
